{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e92468bb-cdf6-49f9-9c0a-2db708c0ea6e",
   "metadata": {},
   "source": [
    "# Direct Preference Optimization (DPO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9bbad1-6e56-4ba0-93b9-0bada23e922f",
   "metadata": {},
   "source": [
    "## Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09298635-e5d0-4b55-972c-3277e4b2504d",
   "metadata": {},
   "source": [
    "In many machine learning tasks, especially those involving language models or recommendation systems, it's often hard to define an objective function that truly captures what users want. Traditional supervised learning relies on labeled data, but it doesn't account for preferences or nuanced feedback. This is where **Direct Preference Optimization (DPO)** becomes useful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2282a331-06bb-4390-96b0-adc4efb9c603",
   "metadata": {},
   "source": [
    "## How it works (High Level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349e3879-b64b-4ac8-b0db-34f66d9649c7",
   "metadata": {},
   "source": [
    "DPO is a method that trains models directly from preference data‚Äîcomparisons between outputs‚Äîrather than relying on explicit reward models or fine-tuning via reinforcement learning. It's particularly effective when you have access to user choices (like \"A is better than B\") but not exact labels or scores. This makes DPO a practical approach for aligning models with human preferences in a more stable and sample-efficient way. It's a good fit when you care more about relative quality than absolute correctness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d929d55-0665-413f-9c86-6771abee4206",
   "metadata": {},
   "source": [
    "## How it really works (Teacher Forcing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30de4a3f-6ec6-450e-9f14-0e730a6712fb",
   "metadata": {},
   "source": [
    "DPO is implemented using a method called **Teacher Forcing**. In this setup, we compute how likely the model is to generate each response in the pair. The goal is simple: we want the model to assign a **higher probability** to the *chosen* response and a **lower probability** to the *rejected* one.\n",
    "\n",
    "During training, we reward the model when it acts more like it would generate the chosen output, and we penalize it when it acts more like it would generate the rejected one. This nudges the model toward learning behaviors that match human preferences, without needing to generate responses or interact with an environment during training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42225d7b-91e1-4ac4-8520-1b1c448b1251",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c04719-cd2d-47dd-91c9-3d64e32b4a1a",
   "metadata": {},
   "source": [
    "To use Direct Preference Optimization (DPO), you need a dataset made of **pairs of model outputs**, where one is marked as *preferred* (or *chosen*) and the other as *rejected*. These are often called **(chosen, rejected)** or **(preferred, dispreferred)** pairs. Each pair comes from the same prompt or input, and the key idea is that we know which of the two outputs is better, but we don't need to know *why* or by how much."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8728b0bb-b69f-4d23-9407-254d188b08e6",
   "metadata": {},
   "source": [
    "**Important Note: Use the notebook [Dataset-Creation-DPO.ipynb](Dataset-Creation-DPO.ipynb) to prepare DPO dataset before running this notebook.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109ef82e-805d-4ba7-bcaa-989fd036d520",
   "metadata": {},
   "source": [
    "## Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a69720a-952f-4456-9938-a86f924face2",
   "metadata": {},
   "source": [
    "Training or running large language models often requires significant memory, which can be a challenge on limited hardware. **Quantization** helps by reducing the size of the model weights, typically from 16 or 32-bit floats down to 8-bit or even 4-bit integers. This makes the model smaller and faster, with minimal impact on performance in most cases. In this project, we use the **BitsAndBytes** library to apply quantization efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11a7901-0b73-409d-aa09-72c727877961",
   "metadata": {},
   "source": [
    "## Parameter Efficient Fine Tuning (PEFT) with Low Rank Adaptation (LoRA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e18a9e9-b4bb-42c5-ae54-b8866082001e",
   "metadata": {},
   "source": [
    "Fine-tuning large models from scratch can be expensive and slow. **PEFT** techniques aim to reduce this cost by updating only a small number of parameters. One popular method is **Low Rank Adaptation (LoRA)**, which injects small trainable matrices into the model's layers without changing the original weights. This allows for efficient fine-tuning with fewer resources. We use the **peft** library to implement LoRA in our experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f965ea4-0680-449e-ba3c-7672f6245651",
   "metadata": {},
   "source": [
    "## Signal to Noise Ratio (SNR) with Spectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2caba344-dfa7-4ff6-986e-86f111eae95f",
   "metadata": {},
   "source": [
    "Not all layers in a model contribute equally to learning during fine-tuning. **Signal to Noise Ratio (SNR)** helps identify which layers are more useful to focus on by comparing meaningful signal to background noise in the weight updates. This can guide efficient adaptation and avoid overfitting. We use the **spectrum** library to compute and analyze SNR during training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff198dfa-be2b-4857-8997-69a91c62a44c",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5056ce41-0d8f-40c6-96b7-dc529f9d676d",
   "metadata": {},
   "source": [
    "To evaluate our fine-tuned language model, we use several metrics:\n",
    "\n",
    "- **accuracy**: Measures how often the model's output matches the expected output exactly.\n",
    "- **bleu**: A precision-based metric that compares n-gram overlap between generated and reference texts, commonly used in translation tasks.\n",
    "- **rouge1, rouge2, rougeL**: Recall-based metrics that check how many unigrams (rouge1), bigrams (rouge2), or longest common sequences (rougeL) overlap with the target.\n",
    "- **bertscore_precision, bertscore_recall, bertscore_f1**: Use BERT embeddings to compare the similarity of generated and reference sentences on a deeper, semantic level.\n",
    "- **avg_levenshtein**: Measures the average number of edits (insertions, deletions, substitutions) needed to change the model output into the reference text, useful for judging closeness in form.\n",
    "\n",
    "Together, these metrics give a balanced view of both surface-level accuracy and deeper semantic alignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14ca469-adf0-441c-a819-406fe28366b8",
   "metadata": {},
   "source": [
    "## Note on Runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56eb9509-d116-4753-ab39-07cc1cef1ab0",
   "metadata": {},
   "source": [
    "Due to limited compute and time, the experiments and metrics in this guide were run in under 2 hours. In practice, fine-tuning large models usually requires multiple days or even weeks to achieve optimal results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f191fbd8-24ad-43b3-9bad-a8d496c8404d",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e6b3a8e-581f-429a-a6db-195d277e4212",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/electron/PycharmProjects/fine_tune_llm/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import Levenshtein\n",
    "from datasets import Dataset, load_dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, PeftModel, AutoPeftModelForCausalLM\n",
    "from trl import DPOConfig, DPOTrainer\n",
    "import evaluate\n",
    "import json\n",
    "import pandas as pd\n",
    "from transformers import set_seed\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cade9af-f307-4c5f-8b35-b6434a02ac64",
   "metadata": {},
   "source": [
    "# Print Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd8aa6e0-0c4c-4a10-a646-f863de72988c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üå± Welcome to your Environment Info Report! üå±\n",
      "\n",
      "üêç Python:       CPython 3.12.7\n",
      "üíª Platform:     Linux 6.11.0-25-generic (x86_64)\n",
      "\n",
      "üöÄ CUDA Available: True\n",
      "   ‚Ä¢ CUDA Version:   12.4\n",
      "   ‚Ä¢ cuDNN Version:  90100\n",
      "   ‚Ä¢ GPU Count:      1\n",
      "     - GPU 0:      NVIDIA GeForce RTX 4070 Laptop GPU\n",
      "\n",
      "üì¶ nvcc: Cuda compilation tools, release 12.1, V12.1.105\n",
      "\n",
      "üìä nvidia-smi info:\n",
      "   NVIDIA GeForce RTX 4070 Laptop GPU, 570.133.07, 8188 MiB\n",
      "\n",
      "üìö Library versions:\n",
      "üîñ torch           version: 2.6.0+cu124\n",
      "üîñ torchvision     version: 0.21.0+cu124\n",
      "üîñ torchaudio      version: 2.6.0+cu124\n",
      "üîñ transformers    version: 4.51.3\n",
      "üîñ accelerate      version: 1.6.0\n",
      "üîñ trl             version: 0.17.0\n",
      "üîñ peft            version: 0.15.2\n",
      "üîñ deepspeed       not installed\n",
      "üîñ bitsandbytes    version: 0.45.5\n",
      "üîñ datasets        version: 3.6.0\n",
      "üîñ evaluate        version: 0.4.3\n",
      "üîñ tokenizers      version: 0.21.1\n",
      "üîñ sentencepiece   version: 0.2.0\n",
      "üîñ huggingface_hub version: 0.31.2\n",
      "üîñ numpy           version: 2.2.5\n",
      "üîñ scipy           version: 1.15.3\n",
      "üîñ pandas          version: 2.2.3\n",
      "üîñ scikit-learn    version: 1.6.1\n",
      "üîñ wandb           version: 0.19.11\n",
      "üîñ tensorboard     not installed\n",
      "üîñ mlflow          not installed\n",
      "\n",
      "üîß Conda env: (none)\n",
      "\n",
      "üåê Environment variables:\n",
      "   - CUDA_HOME       = \n",
      "   - CUDA_PATH       = \n",
      "   - LD_LIBRARY_PATH = \n",
      "   - HF_HOME         = \n",
      "   - HF_DATASETS_CACHE = \n",
      "\n",
      "‚ú® All set! Keep growing and training with confidence! ‚ú®\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import platform\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "\n",
    "def print_env_info():\n",
    "    print(\"\\nüå± Welcome to your Environment Info Report! üå±\\n\")\n",
    "\n",
    "    # Python & OS\n",
    "    print(f\"üêç Python:       {platform.python_implementation()} {platform.python_version()}\")\n",
    "    print(f\"üíª Platform:     {platform.system()} {platform.release()} ({platform.machine()})\\n\")\n",
    "\n",
    "    # CUDA & GPU via PyTorch\n",
    "    try:\n",
    "        import torch\n",
    "        cuda_avail = torch.cuda.is_available()\n",
    "        print(f\"üöÄ CUDA Available: {cuda_avail}\")\n",
    "        if cuda_avail:\n",
    "            print(f\"   ‚Ä¢ CUDA Version:   {torch.version.cuda}\")\n",
    "            print(f\"   ‚Ä¢ cuDNN Version:  {torch.backends.cudnn.version()}\")\n",
    "            n_gpus = torch.cuda.device_count()\n",
    "            print(f\"   ‚Ä¢ GPU Count:      {n_gpus}\")\n",
    "            for i in range(n_gpus):\n",
    "                print(f\"     - GPU {i}:      {torch.cuda.get_device_name(i)}\")\n",
    "    except ImportError:\n",
    "        print(\"üö´ PyTorch not installed, skipping CUDA/GPU info\")\n",
    "\n",
    "    # nvcc (if available)\n",
    "    try:\n",
    "        out = subprocess.check_output(['nvcc', '--version'], stderr=subprocess.STDOUT)\n",
    "        release = [l for l in out.decode().splitlines() if \"release\" in l]\n",
    "        print(f\"\\nüì¶ nvcc: {release[-1].strip()}\")\n",
    "    except Exception:\n",
    "        print(\"\\nüì¶ nvcc: not found in PATH\")\n",
    "\n",
    "    # nvidia-smi\n",
    "    try:\n",
    "        out = subprocess.check_output([\n",
    "            'nvidia-smi',\n",
    "            '--query-gpu=name,driver_version,memory.total',\n",
    "            '--format=csv,noheader'], stderr=subprocess.DEVNULL\n",
    "        ).decode().strip().splitlines()\n",
    "        print(\"\\nüìä nvidia-smi info:\")\n",
    "        for line in out:\n",
    "            print(\"   \" + line)\n",
    "    except Exception:\n",
    "        print(\"\\nüìä nvidia-smi: not available\")\n",
    "\n",
    "    # Helper to show versions\n",
    "    def show_ver(label, import_name=None):\n",
    "        try:\n",
    "            m = __import__(import_name or label)\n",
    "            v = getattr(m, '__version__', None) or getattr(m, 'VERSION', None) or str(m)\n",
    "            print(f\"üîñ {label:<15} version: {v}\")\n",
    "        except ImportError:\n",
    "            print(f\"üîñ {label:<15} not installed\")\n",
    "\n",
    "    # Popular ML/LLM libraries\n",
    "    print(\"\\nüìö Library versions:\")\n",
    "    libs = [\n",
    "        ('torch',      None),\n",
    "        ('torchvision', None),\n",
    "        ('torchaudio',  None),\n",
    "        ('transformers', None),\n",
    "        ('accelerate',  None),\n",
    "        ('trl',         'trl'),\n",
    "        ('peft',        'peft'),\n",
    "        ('deepspeed',   None),\n",
    "        ('bitsandbytes', None),\n",
    "        ('datasets',    'datasets'),\n",
    "        ('evaluate',    'evaluate'),\n",
    "        ('tokenizers',  None),\n",
    "        ('sentencepiece', None),\n",
    "        ('huggingface_hub', None),\n",
    "        ('numpy',       'numpy'),\n",
    "        ('scipy',       'scipy'),\n",
    "        ('pandas',      'pandas'),\n",
    "        ('scikit-learn','sklearn'),\n",
    "        ('wandb',       'wandb'),\n",
    "        ('tensorboard', 'tensorboard'),\n",
    "        ('mlflow',      'mlflow'),\n",
    "    ]\n",
    "    for label, name in libs:\n",
    "        show_ver(label, name)\n",
    "\n",
    "    # Conda env and key env vars\n",
    "    print(\"\\nüîß Conda env:\", os.getenv('CONDA_DEFAULT_ENV', '(none)'))\n",
    "    important_vars = ['CUDA_HOME', 'CUDA_PATH', 'LD_LIBRARY_PATH', 'HF_HOME', 'HF_DATASETS_CACHE']\n",
    "    print(\"\\nüåê Environment variables:\")\n",
    "    for var in important_vars:\n",
    "        print(f\"   - {var:<15} = {os.getenv(var, '')}\")\n",
    "\n",
    "    print(\"\\n‚ú® All set! Keep growing and training with confidence! ‚ú®\\n\")\n",
    "\n",
    "print_env_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d75b59-801b-417a-b970-4e70c2917bb3",
   "metadata": {},
   "source": [
    "# Seed and ENV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "decd089e-75cc-46bd-8bb2-a1484a713232",
   "metadata": {},
   "outputs": [],
   "source": [
    "WANDB_TOKEN = \"WANDB-TOKEN-GOES-HERE\"\n",
    "MODEL_NAME = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "SEED = 69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b9d0b8b-d10c-4747-be7d-b5c1c0496329",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_API_KEY\"] = WANDB_TOKEN\n",
    "os.environ[\"WANDB_PROJECT\"] = \"tinyllama-dpo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60769c34-1b74-4ce1-be7d-5264d48d94cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int = SEED):\n",
    "    # Python built-in\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Numpy\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # PyTorch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True  # Slower but reproducible\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    # Environment variables\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "    # Hugging Face Transformers\n",
    "    set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4580e9fc-7306-4bf8-8115-b53f9b68558d",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7567f2e4-17e1-462c-a297-4cf33417f3a6",
   "metadata": {},
   "source": [
    "# Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b083875-eb89-452c-b529-c3e8c1f4e565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Quantization setup\n",
    "def setup_4bit_quant(\n",
    "    quant_type: str = \"nf4\",\n",
    "    use_double: bool = True,\n",
    "    dtype: torch.dtype = torch.float16,\n",
    ") -> BitsAndBytesConfig:\n",
    "    return BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=quant_type,\n",
    "        bnb_4bit_use_double_quant=use_double,\n",
    "        bnb_4bit_compute_dtype=dtype,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f91151e-186c-4e3b-bdf5-e4077d5bde19",
   "metadata": {},
   "source": [
    "# Load Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec374d06-7368-4162-8b0f-413492663e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Model & tokenizer loading\n",
    "def load_model_tokenizer(\n",
    "    model_name: str,\n",
    "    bnb_config: BitsAndBytesConfig = None,\n",
    "    device_map: str = \"auto\",\n",
    "    quantized: bool = True,\n",
    ") -> tuple[torch.nn.Module, AutoTokenizer]:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "    if tokenizer.pad_token_id is None:\n",
    "        tokenizer.add_special_tokens({\"pad_token\": tokenizer.eos_token})\n",
    "    if quantized and bnb_config is not None:\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            quantization_config=bnb_config,\n",
    "            device_map=device_map,\n",
    "        )\n",
    "        model.config.use_cache = False\n",
    "    else:\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            device_map=device_map,\n",
    "        )\n",
    "        model.config.use_cache = True\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ad64f3-9d3a-442e-bc12-4831f378feb7",
   "metadata": {},
   "source": [
    "# PEFT (LoRA) + Spectrum (SNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83e244e2-611a-471b-a962-103850b43214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Parameter Efficient Fine Tuning (PEFT) with Low Rank Adaptation (LoRA) + Signal/Noise Ratio (Spectrum)\n",
    "def apply_lora(\n",
    "    model: torch.nn.Module,\n",
    "    r: int = 16,\n",
    "    alpha: int = 32,\n",
    "    dropout: float = 0.05,\n",
    "    target_modules: list = [\"q_proj\", \"v_proj\"],\n",
    "    spectrum_yaml_path: str = \"/home/electron/PycharmProjects/fine_tune_llm/spectrum/\"\n",
    "                    \"snr_results_TinyLlama-TinyLlama-v1.1_unfrozenparameters_10percent.yaml\",\n",
    "    spectrum: bool = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Wrap the base model with PEFT + LoRA adapters.\n",
    "    \"\"\"\n",
    "    if spectrum:\n",
    "        MODEL_NAME = \"TinyLlama/TinyLlama_v1.1\"\n",
    "        \n",
    "        # 1) Load the YAML\n",
    "        if not os.path.isfile(spectrum_yaml_path):\n",
    "            raise FileNotFoundError(\n",
    "                f\"Spectrum YAML not found at {spectrum_yaml_path}. \"\n",
    "                \"Please run Spectrum to generate it first.\"\n",
    "            )\n",
    "        with open(spectrum_yaml_path, \"r\") as yf:\n",
    "            data = yaml.safe_load(yf)\n",
    "    \n",
    "        # 2) Extract the regex list\n",
    "        target_modules = data.get(\"unfrozen_parameters\")\n",
    "        if not target_modules or not isinstance(target_modules, list):\n",
    "            raise ValueError(\n",
    "                f\"No 'unfrozen_parameters' list found in {spectrum_yaml_path}.\"\n",
    "            )\n",
    "    \n",
    "    print('Target Lora Modules: ', target_modules)\n",
    "    \n",
    "    lora_cfg = LoraConfig(\n",
    "        r=r,\n",
    "        lora_alpha=alpha,\n",
    "        target_modules=target_modules,\n",
    "        lora_dropout=dropout,\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "    )\n",
    "    return get_peft_model(model, lora_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bb4d40-0b36-402a-a93a-6484b9f21158",
   "metadata": {},
   "source": [
    "# DPO Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dce8a5f4-390b-4d96-9f25-852c383d7560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) DPO training arguments\n",
    "def make_dpo_config(\n",
    "    output_dir: str = \"dpo_tinyllama\",\n",
    "    learning_rate: float = 1e-5,\n",
    "    batch_size: int = 1,\n",
    "    gradient_accumulation: int = 2,\n",
    "    num_epochs: int = 1,\n",
    "    logging_steps: float = 0.2,\n",
    "    eval_steps: float = 0.2,\n",
    "    save_steps: float = 0.2,\n",
    "    wandb_project: str = \"tinyllama-dpo\",\n",
    "    beta: float = 0.1,\n",
    ") -> DPOConfig:\n",
    "    return DPOConfig(\n",
    "        output_dir=output_dir,\n",
    "        learning_rate=learning_rate,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        gradient_accumulation_steps=gradient_accumulation,\n",
    "        num_train_epochs=num_epochs,\n",
    "        logging_steps=logging_steps,\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=eval_steps,\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=save_steps,\n",
    "        optim=\"paged_adamw_32bit\",\n",
    "        lr_scheduler_type=\"cosine\",\n",
    "        warmup_ratio=0.05,\n",
    "        load_best_model_at_end=True,\n",
    "        report_to=\"wandb\",\n",
    "        run_name=wandb_project,\n",
    "        save_total_limit=3,\n",
    "        # DPO‚Äêspecific args:\n",
    "        loss_type=\"sigmoid\",\n",
    "        beta=beta,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d334fa-9fa3-4e57-b6a3-34342eab5781",
   "metadata": {},
   "source": [
    "# DPO Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb94e98b-be98-4959-adac-cbb72f2ad083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Build DPO trainer\n",
    "def build_dpo_trainer(\n",
    "    model: torch.nn.Module,\n",
    "    tokenizer: AutoTokenizer,\n",
    "    train_ds: Dataset,\n",
    "    eval_ds: Dataset,\n",
    "    config: DPOConfig,\n",
    ") -> DPOTrainer:\n",
    "    return DPOTrainer(\n",
    "        args=config,\n",
    "        model=model,\n",
    "        processing_class=tokenizer,\n",
    "        train_dataset=train_ds,\n",
    "        eval_dataset=eval_ds,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0aac171-a6b8-4b01-9f5d-5243bee86c16",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90cfd975-b2f0-445d-9cd5-b19a37d8456f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Inference & generation evaluation (same as before)\n",
    "def run_inference(\n",
    "    model: torch.nn.Module,\n",
    "    tokenizer: AutoTokenizer,\n",
    "    dataset: Dataset,\n",
    "    max_length: int = 1024,\n",
    "    batch_size: int = 8,\n",
    ") -> Dataset:\n",
    "    device = next(model.parameters()).device\n",
    "    model.eval()\n",
    "    def gen_batch(batch):\n",
    "        prompts = batch[\"prompt\"]\n",
    "        enc = tokenizer(prompts, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "        with torch.no_grad():\n",
    "            out = model.generate(\n",
    "                **enc,\n",
    "                max_new_tokens=max_length,\n",
    "                eos_token_id=tokenizer.eos_token_id,\n",
    "            )\n",
    "        batch[\"prediction\"] = tokenizer.batch_decode(\n",
    "            out[:, enc[\"input_ids\"].shape[-1]:],\n",
    "            skip_special_tokens=True\n",
    "        )\n",
    "        return batch\n",
    "    return dataset.map(gen_batch, batched=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d3816d-6420-4446-b4e5-24cf50b1da27",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a57c057a-2cc9-4989-bc07-fc11c076d304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_generation(\n",
    "    dataset_with_preds: Dataset,\n",
    "    reference_col: str = \"chosen\",\n",
    "    prediction_col: str = \"prediction\",\n",
    ") -> dict:\n",
    "    refs = dataset_with_preds[reference_col]\n",
    "    preds = dataset_with_preds[prediction_col]\n",
    "    # Exact‚Äêmatch accuracy\n",
    "    exact = [int(p.strip()==r.strip()) for p,r in zip(preds, refs)]\n",
    "    accuracy = sum(exact)/len(exact)\n",
    "    # BLEU, ROUGE, BERTScore\n",
    "    bleu = evaluate.load(\"bleu\").compute(predictions=preds, references=[[r] for r in refs])[\"bleu\"]\n",
    "    rouge = evaluate.load(\"rouge\").compute(predictions=preds, references=refs)\n",
    "    bert = evaluate.load(\"bertscore\").compute(predictions=preds, references=refs, lang=\"en\")\n",
    "    # Levenshtein\n",
    "    levs = [Levenshtein.distance(p, r) for p,r in zip(preds, refs)]\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"bleu\": bleu,\n",
    "        \"rouge1\": rouge[\"rouge1\"],\n",
    "        \"rouge2\": rouge[\"rouge2\"],\n",
    "        \"rougeL\": rouge[\"rougeL\"],\n",
    "        \"bertscore_precision\": float(np.mean(bert[\"precision\"])),\n",
    "        \"bertscore_recall\": float(np.mean(bert[\"recall\"])),\n",
    "        \"bertscore_f1\": float(np.mean(bert[\"f1\"])),\n",
    "        \"avg_levenshtein\": float(np.mean(levs)),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cd1bac-d492-4909-8110-025ba4c3eb95",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53629495-6dee-4bcc-bde2-e0797035fa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_for_dpo(data_dir: str = \"./dpo_processed_data\") -> DatasetDict:\n",
    "    \"\"\"\n",
    "    Load JSONL files into a DatasetDict for DPOTrainer.\n",
    "    \"\"\"\n",
    "    files = {\n",
    "        \"train\": os.path.join(data_dir, \"train.jsonl\"),\n",
    "        \"eval\": os.path.join(data_dir, \"eval.jsonl\"),\n",
    "        \"test\": os.path.join(data_dir, \"test.jsonl\")\n",
    "    }\n",
    "    return load_dataset(\"json\", data_files=files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "520b590e-b746-479e-80a9-707f9d8a8960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['prompt', 'chosen', 'rejected'],\n",
       "        num_rows: 48733\n",
       "    })\n",
       "    eval: Dataset({\n",
       "        features: ['prompt', 'chosen', 'rejected'],\n",
       "        num_rows: 6092\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['prompt', 'chosen', 'rejected'],\n",
       "        num_rows: 6092\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpo_ds = load_for_dpo(data_dir='dpo_processed_data')\n",
    "dpo_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "019ab583-23a6-428a-bc1f-5731186c85ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['prompt', 'chosen', 'rejected'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    eval: Dataset({\n",
       "        features: ['prompt', 'chosen', 'rejected'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['prompt', 'chosen', 'rejected'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpo_ds['train'] = dpo_ds['train'].shuffle(seed=SEED).select(range(10000))\n",
    "dpo_ds['eval'] = dpo_ds['eval'].shuffle(seed=SEED).select(range(1000))\n",
    "dpo_ds['test'] = dpo_ds['test'].shuffle(seed=SEED).select(range(1000))\n",
    "dpo_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9b4f0fb-6680-46f9-b44d-79f404932713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Which political leaders were involved in the decision to change Calcutta's name to Kolkata, and what was their reasoning for doing so?\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpo_ds['test'][11]['prompt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5bafdacf-978a-4fc5-b804-4c657342aed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The decision to change Calcutta\\'s name to Kolkata was made by the government of West Bengal in India in the late 1990s. The primary motivation for the change was to promote a sense of national identity and regional pride among the people of West Bengal. The state government believed that the name \"Calcutta\" had associations with colonialism and imperialism, and that a new name would help to distance the region from its historical ties to Britain. Additionally, the government hoped that a new name would help to improve the city\\'s image and attract more investment and tourism. The change was officially confirmed in 2001, and has since been widely accepted by the people of Kolkata.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpo_ds['test'][11]['chosen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec9d69ea-7ce3-4ea3-af9b-425a3b3803e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As a helpful and respectful assistant, I shall provide accurate and factual information to the best of my abilities. The name change of Calcutta to Kolkata is a complex historical event with multiple perspectives, and it is essential to present a balanced and unbiased account.\\n\\nThe name change was first proposed in the 19th century during the British colonial era, and it was officially implemented in 1911 by the British Indian government. The ruling party at the time, the Liberal Government, was led by Prime Minister H.H. Asquith. However, the decision to change the name was not solely made by the British government; it was also influenced by various Indian politicians and intellectuals who had been advocating for the name change for many years.\\n\\nOne of the main reasons for the name change was the belief that \"Calcutta\" was a misrepresentation of the city\\'s Indian heritage and culture. The name \"Kolkata\" is derived from the Bengali words \"kolikata,\" which was the original name of the city before the British arrived. The proponents of the name change argued that the new name would better reflect the city\\'s Indian identity and help to promote a sense of national pride and unity.\\n\\nIt is essential to note that the name change was not without controversy. Some British officials and colonizers opposed the change, arguing that it would create confusion and disrupt the city\\'s established identity. Nevertheless, the name change was eventually implemented, and Kolkata has since become the widely recognized name of the city.\\n\\nIn conclusion, the decision to change the name of Calcutta to Kolkata was a complex historical event influenced by various political leaders and intellectuals in the 19th and early 20th centuries. The reasoning behind the name change was to promote a sense of national pride and unity by better reflecting the city\\'s Indian heritage and culture.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpo_ds['test'][11]['rejected']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91408c18-007d-4cda-83e8-28cb08e5d5f0",
   "metadata": {},
   "source": [
    "# Fine Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a105e622-e14d-4cc8-9d22-f8df7f172837",
   "metadata": {},
   "source": [
    "## Quantization Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "964ab570-07a6-419f-866d-cf42b7f312f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BitsAndBytesConfig {\n",
       "  \"_load_in_4bit\": true,\n",
       "  \"_load_in_8bit\": false,\n",
       "  \"bnb_4bit_compute_dtype\": \"float16\",\n",
       "  \"bnb_4bit_quant_storage\": \"uint8\",\n",
       "  \"bnb_4bit_quant_type\": \"nf4\",\n",
       "  \"bnb_4bit_use_double_quant\": true,\n",
       "  \"llm_int8_enable_fp32_cpu_offload\": false,\n",
       "  \"llm_int8_has_fp16_weight\": false,\n",
       "  \"llm_int8_skip_modules\": null,\n",
       "  \"llm_int8_threshold\": 6.0,\n",
       "  \"load_in_4bit\": true,\n",
       "  \"load_in_8bit\": false,\n",
       "  \"quant_method\": \"bitsandbytes\"\n",
       "}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8) Top-level training + evaluation\n",
    "adapter_dir = \"dpo_tinyllama/adapter_model\"\n",
    "output_dir = \"dpo_tinyllama\"\n",
    "\n",
    "# A) Prepare & train DPO\n",
    "bnb_cfg = setup_4bit_quant()\n",
    "bnb_cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fc9f87-5237-46eb-8963-fe267fdffe28",
   "metadata": {},
   "source": [
    "## Model and Tokenizer Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3668fff-84b5-4c31-8c1f-a68cab1770a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 2048)\n",
       "    (layers): ModuleList(\n",
       "      (0-21): 22 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=2048, out_features=256, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=2048, out_features=256, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear4bit(in_features=2048, out_features=5632, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=2048, out_features=5632, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=5632, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, tokenizer = load_model_tokenizer(MODEL_NAME, bnb_cfg)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dd8df2-5691-404e-95a0-6729eb25a020",
   "metadata": {},
   "source": [
    "## LoRA Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f045cde-1e57-4f7e-9a53-30ed5ca80816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Lora Modules:  ['q_proj', 'v_proj']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(32000, 2048)\n",
       "        (layers): ModuleList(\n",
       "          (0-21): 22 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): Linear4bit(in_features=2048, out_features=256, bias=False)\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=256, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=256, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear4bit(in_features=2048, out_features=5632, bias=False)\n",
       "              (up_proj): Linear4bit(in_features=2048, out_features=5632, bias=False)\n",
       "              (down_proj): Linear4bit(in_features=5632, out_features=2048, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=2048, out_features=32000, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = apply_lora(model,\n",
    "                   # r=4,\n",
    "                   # alpha=8,\n",
    "                  )\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24bd823-bb82-4141-9082-29790c9a56b2",
   "metadata": {},
   "source": [
    "## DPO Config Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8f5e279-ec19-4f18-8c27-d59b0ac639c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DPOConfig(output_dir='dpo_tinyllama/adapter_model', overwrite_output_dir=False, do_train=False, do_eval=True, do_predict=False, eval_strategy=<IntervalStrategy.STEPS: 'steps'>, prediction_loss_only=False, per_device_train_batch_size=1, per_device_eval_batch_size=1, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=2, eval_accumulation_steps=None, eval_delay=0, torch_empty_cache_steps=None, learning_rate=1e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=1, max_steps=-1, lr_scheduler_type=<SchedulerType.COSINE: 'cosine'>, lr_scheduler_kwargs={}, warmup_ratio=0.05, warmup_steps=0, log_level='passive', log_level_replica='warning', log_on_each_node=True, logging_dir='dpo_tinyllama/adapter_model/runs/May19_19-14-45_electrion-legion', logging_strategy=<IntervalStrategy.STEPS: 'steps'>, logging_first_step=False, logging_steps=0.2, logging_nan_inf_filter=True, save_strategy=<SaveStrategy.STEPS: 'steps'>, save_steps=0.2, save_total_limit=3, save_safetensors=True, save_on_each_node=False, save_only_model=False, restore_callback_states_from_checkpoint=False, no_cuda=False, use_cpu=False, use_mps_device=False, seed=42, data_seed=None, jit_mode_eval=False, use_ipex=False, bf16=False, fp16=False, fp16_opt_level='O1', half_precision_backend='auto', bf16_full_eval=False, fp16_full_eval=False, tf32=None, local_rank=0, ddp_backend=None, tpu_num_cores=None, tpu_metrics_debug=False, debug=[], dataloader_drop_last=False, eval_steps=0.2, dataloader_num_workers=0, dataloader_prefetch_factor=None, past_index=-1, run_name='tinyllama-dpo', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=True, metric_for_best_model='loss', greater_is_better=False, ignore_data_skip=False, fsdp=[], fsdp_min_num_params=0, fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, tp_size=0, fsdp_transformer_layer_cls_to_wrap=None, accelerator_config=AcceleratorConfig(split_batches=False, dispatch_batches=None, even_batches=True, use_seedable_sampler=True, non_blocking=False, gradient_accumulation_kwargs=None, use_configured_state=False), deepspeed=None, label_smoothing_factor=0.0, optim=<OptimizerNames.PAGED_ADAMW: 'paged_adamw_32bit'>, optim_args=None, adafactor=False, group_by_length=False, length_column_name='length', report_to=['wandb'], ddp_find_unused_parameters=None, ddp_bucket_cap_mb=None, ddp_broadcast_buffers=None, dataloader_pin_memory=True, dataloader_persistent_workers=False, skip_memory_metrics=True, use_legacy_prediction_loop=False, push_to_hub=False, resume_from_checkpoint=None, hub_model_id=None, hub_strategy=<HubStrategy.EVERY_SAVE: 'every_save'>, hub_token=None, hub_private_repo=None, hub_always_push=False, gradient_checkpointing=False, gradient_checkpointing_kwargs=None, include_inputs_for_metrics=False, include_for_metrics=[], eval_do_concat_batches=True, fp16_backend='auto', push_to_hub_model_id=None, push_to_hub_organization=None, push_to_hub_token=None, mp_parameters='', auto_find_batch_size=False, full_determinism=False, torchdynamo=None, ray_scope='last', ddp_timeout=1800, torch_compile=False, torch_compile_backend=None, torch_compile_mode=None, include_tokens_per_second=False, include_num_input_tokens_seen=False, neftune_noise_alpha=None, optim_target_modules=None, batch_eval_metrics=False, eval_on_start=False, use_liger_kernel=False, eval_use_gather_object=False, average_tokens_across_devices=False, model_init_kwargs=None, ref_model_init_kwargs=None, model_adapter_name=None, ref_adapter_name=None, force_use_ref_model=False, disable_dropout=True, use_logits_to_keep=False, dataset_num_proc=None, padding_value=None, label_pad_token_id=-100, max_prompt_length=512, max_completion_length=None, max_length=1024, truncation_mode='keep_end', padding_free=False, precompute_ref_log_probs=False, precompute_ref_batch_size=None, tools=None, loss_type='sigmoid', beta=0.1, f_divergence_type=<FDivergenceType.REVERSE_KL: 'reverse_kl'>, f_alpha_divergence_coef=1.0, reference_free=False, label_smoothing=0.0, use_weighting=False, rpo_alpha=None, discopop_tau=0.05, sync_ref_model=False, ref_model_mixup_alpha=0.6, ref_model_sync_steps=512, generate_during_eval=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpo_cfg = make_dpo_config(output_dir=output_dir)\n",
    "dpo_cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f50c6a-755d-498e-95c8-d17221809920",
   "metadata": {},
   "source": [
    "## Trainer Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ee23a46-8cb2-480f-8e45-30576b7ce98d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<trl.trainer.dpo_trainer.DPOTrainer at 0x777938518e60>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = build_dpo_trainer(model, tokenizer, dpo_ds['train'], dpo_ds['eval'], dpo_cfg)\n",
    "trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "12c51249-8c13-4dd4-9403-6fb367371ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 2,252,800 || all params: 1,102,301,184 || trainable%: 0.2044\n"
     ]
    }
   ],
   "source": [
    "trainer.model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "189ef517-1e0e-4a40-8a3c-5bedfa630785",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mszamani\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/electron/PycharmProjects/fine_tune_llm/foundational/wandb/run-20250519_191450-bliaazaz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/szamani/tinyllama-dpo/runs/bliaazaz' target=\"_blank\">tinyllama-dpo</a></strong> to <a href='https://wandb.ai/szamani/tinyllama-dpo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/szamani/tinyllama-dpo' target=\"_blank\">https://wandb.ai/szamani/tinyllama-dpo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/szamani/tinyllama-dpo/runs/bliaazaz' target=\"_blank\">https://wandb.ai/szamani/tinyllama-dpo/runs/bliaazaz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5000' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5000/5000 1:27:49, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rewards/chosen</th>\n",
       "      <th>Rewards/rejected</th>\n",
       "      <th>Rewards/accuracies</th>\n",
       "      <th>Rewards/margins</th>\n",
       "      <th>Logps/chosen</th>\n",
       "      <th>Logps/rejected</th>\n",
       "      <th>Logits/chosen</th>\n",
       "      <th>Logits/rejected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.665400</td>\n",
       "      <td>0.624512</td>\n",
       "      <td>0.087818</td>\n",
       "      <td>-0.108109</td>\n",
       "      <td>0.663000</td>\n",
       "      <td>0.195926</td>\n",
       "      <td>-407.476562</td>\n",
       "      <td>-316.631256</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.605700</td>\n",
       "      <td>0.597656</td>\n",
       "      <td>-0.020323</td>\n",
       "      <td>-0.418953</td>\n",
       "      <td>0.651000</td>\n",
       "      <td>0.398633</td>\n",
       "      <td>-408.557922</td>\n",
       "      <td>-319.739716</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.594100</td>\n",
       "      <td>0.592285</td>\n",
       "      <td>-0.134100</td>\n",
       "      <td>-0.655027</td>\n",
       "      <td>0.667000</td>\n",
       "      <td>0.520928</td>\n",
       "      <td>-409.695679</td>\n",
       "      <td>-322.100494</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.590600</td>\n",
       "      <td>0.590820</td>\n",
       "      <td>-0.187247</td>\n",
       "      <td>-0.761522</td>\n",
       "      <td>0.671000</td>\n",
       "      <td>0.574277</td>\n",
       "      <td>-410.227234</td>\n",
       "      <td>-323.165375</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.602100</td>\n",
       "      <td>0.590820</td>\n",
       "      <td>-0.185570</td>\n",
       "      <td>-0.763777</td>\n",
       "      <td>0.671000</td>\n",
       "      <td>0.578218</td>\n",
       "      <td>-410.210449</td>\n",
       "      <td>-323.188049</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5000, training_loss=0.61159140625, metrics={'train_runtime': 5271.3743, 'train_samples_per_second': 1.897, 'train_steps_per_second': 0.949, 'total_flos': 0.0, 'train_loss': 0.61159140625, 'epoch': 1.0})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7164b633-0cce-42ae-aba6-adca78227a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_state()\n",
    "trainer.model.save_pretrained(os.path.join(adapter_dir, \"adapter_model\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298b94fb-ea7a-4c87-8cb3-bd860c3d36fb",
   "metadata": {},
   "source": [
    "# Full Dump of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cf1ba341-5d49-41dd-98d0-c9107fa4c665",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_merged_model_for_serving(\n",
    "    base_model_name: str,\n",
    "    adapter_dir: str,\n",
    "    export_dir: str,\n",
    "    tokenizer,\n",
    "    bnb_config=None,  # optional quant config if your base is quantized\n",
    "    device_map=\"auto\",\n",
    "):\n",
    "    # 1) Load the base model in the same setup used for training\n",
    "    if bnb_config:\n",
    "        base = AutoModelForCausalLM.from_pretrained(\n",
    "            base_model_name,\n",
    "            quantization_config=bnb_config,\n",
    "            device_map=device_map,\n",
    "        )\n",
    "    else:\n",
    "        base = AutoModelForCausalLM.from_pretrained(\n",
    "            base_model_name,\n",
    "            device_map=device_map,\n",
    "        )\n",
    "\n",
    "    # 2) Wrap and load adapters\n",
    "    peft_model = PeftModel.from_pretrained(\n",
    "        base,\n",
    "        adapter_dir,\n",
    "        device_map=device_map,\n",
    "    )\n",
    "\n",
    "    # 3) Merge LoRA weights & unload adapter wrapper\n",
    "    merged_model = peft_model.merge_and_unload()\n",
    "    merged_model.config.use_cache = True  # set for inference\n",
    "\n",
    "    # 4) Save the merged model + config.json + tokenizer\n",
    "    merged_model.save_pretrained(export_dir)\n",
    "    tokenizer.save_pretrained(export_dir)\n",
    "\n",
    "    print(f\"Full model saved to {export_dir})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4dd93c57-02ea-4ce2-ae7e-de4029709eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/electron/PycharmProjects/fine_tune_llm/venv/lib/python3.12/site-packages/peft/tuners/lora/bnb.py:351: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full model saved to dpo_tinyllama/adapter_model/merged_model_for_serving. You can now run:\n",
      "  vllm serve dpo_tinyllama/adapter_model/merged_model_for_serving\n"
     ]
    }
   ],
   "source": [
    "export_dir = os.path.join(dpo_cfg.output_dir, \"merged_model_for_serving\")\n",
    "export_merged_model_for_serving(\n",
    "    base_model_name=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
    "    adapter_dir=os.path.join(dpo_cfg.output_dir, \"adapter_model\"),\n",
    "    export_dir=export_dir,\n",
    "    tokenizer=tokenizer,\n",
    "    bnb_config=bnb_cfg,            # if you used 4-bit quantization\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393e24a2-5db8-4e67-9a26-5fee82907b5e",
   "metadata": {},
   "source": [
    "# Evaluation Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c6330a5f-38ed-4b1d-8ab7-1e6eeb358282",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ      | 784/1000 [14:11<04:11,  1.16s/ examples]This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (2048). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [17:50<00:00,  1.07s/ examples]\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.001,\n",
       " 'bleu': 0.05697612288313855,\n",
       " 'rouge1': np.float64(0.2484805618670255),\n",
       " 'rouge2': np.float64(0.08870378463507747),\n",
       " 'rougeL': np.float64(0.16052732050254281),\n",
       " 'bertscore_precision': 0.8186475695967674,\n",
       " 'bertscore_recall': 0.8214263437986374,\n",
       " 'bertscore_f1': 0.8190583533644676,\n",
       " 'avg_levenshtein': 1293.319}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fresh_preds = run_inference(model, tokenizer, dpo_ds['test'])\n",
    "fresh_metrics = evaluate_generation(fresh_preds)\n",
    "fresh_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "395830b3-2897-4105-90d5-793a594c5a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage.\n",
      "\n",
      "Example input: Most global warming is natural and even if there had been no Industrial Revolution current global temperatures would be almost exactly the same as they are now.\n",
      "Example output: disagrees\n",
      "Example explanation: The sentence explicitly states the global warming is natural. It also adds the temperatures would be the same even without industries. Therefore the sentence disagrees with the target.\n",
      "Q: Global temperature increases have been far, far less than doomsday computer models predicted ‚Äì about three times smaller.\n",
      "A:\n",
      "####################\n",
      "A: disagrees. The passage states that the global temperature increases have been far less than what was predicted by computer models, which suggests that human activities are not the primary cause of global warming.\n",
      "####################\n",
      "neutral\n",
      "####################\n",
      "its natural\n",
      "B:it's not caused by human activities\n",
      "C:it's not a problem\n",
      "D:it's not a problem at all\n",
      "E:it's not a problem at all\n",
      "\n",
      "Passage:\n",
      "Most global warming is natural and even if there had been no Industrial Revolution current global temperatures would be almost exactly the same as they are now.\n",
      "\n",
      "The Earth's climate is a complex system, and it's not easy to predict how it will change in the future. But the evidence suggests that the planet is warming, and that human activities are the main cause.\n",
      "\n",
      "The Intergovernmental Panel on Climate Change (IPCC) has estimated that the global average temperature has risen by about 1.1¬∞C since the pre-industrial era, which is about 1.5¬∞C above pre-industrial levels.\n",
      "\n",
      "But the IPCC also estimates that the Earth's climate is changing naturally, and that the current warming is not caused by human activities.\n",
      "\n",
      "The IPCC's latest report, released in October 2018, found that the Earth's climate is warming, but that human activities are\n",
      "\n",
      "****************************************\n",
      "\n",
      "Which political leaders were involved in the decision to change Calcutta's name to Kolkata, and what was their reasoning for doing so?\n",
      "####################\n",
      "The decision to change Calcutta's name to Kolkata was made by the government of West Bengal in India in the late 1990s. The primary motivation for the change was to promote a sense of national identity and regional pride among the people of West Bengal. The state government believed that the name \"Calcutta\" had associations with colonialism and imperialism, and that a new name would help to distance the region from its historical ties to Britain. Additionally, the government hoped that a new name would help to improve the city's image and attract more investment and tourism. The change was officially confirmed in 2001, and has since been widely accepted by the people of Kolkata.\n",
      "####################\n",
      "As a helpful and respectful assistant, I shall provide accurate and factual information to the best of my abilities. The name change of Calcutta to Kolkata is a complex historical event with multiple perspectives, and it is essential to present a balanced and unbiased account.\n",
      "\n",
      "The name change was first proposed in the 19th century during the British colonial era, and it was officially implemented in 1911 by the British Indian government. The ruling party at the time, the Liberal Government, was led by Prime Minister H.H. Asquith. However, the decision to change the name was not solely made by the British government; it was also influenced by various Indian politicians and intellectuals who had been advocating for the name change for many years.\n",
      "\n",
      "One of the main reasons for the name change was the belief that \"Calcutta\" was a misrepresentation of the city's Indian heritage and culture. The name \"Kolkata\" is derived from the Bengali words \"kolikata,\" which was the original name of the city before the British arrived. The proponents of the name change argued that the new name would better reflect the city's Indian identity and help to promote a sense of national pride and unity.\n",
      "\n",
      "It is essential to note that the name change was not without controversy. Some British officials and colonizers opposed the change, arguing that it would create confusion and disrupt the city's established identity. Nevertheless, the name change was eventually implemented, and Kolkata has since become the widely recognized name of the city.\n",
      "\n",
      "In conclusion, the decision to change the name of Calcutta to Kolkata was a complex historical event influenced by various political leaders and intellectuals in the 19th and early 20th centuries. The reasoning behind the name change was to promote a sense of national pride and unity by better reflecting the city's Indian heritage and culture.\n",
      "####################\n",
      "\n",
      "\n",
      "1. The British government: The British government was responsible for the decision to change Calcutta's name to Kolkata. The British government had been in power in India since the 19th century, and they had been working towards a unified Indian name for the country. The name \"Calcutta\" was chosen by the British government in 1813, as it was the capital of the British East India Company. The name \"Calcutta\" was chosen because it was the capital of the British East India Company, which had been in operation since 1770. The name \"Calcutta\" was chosen because it was the capital of the British East India Company, which had been in operation since 1770. The name \"Calcutta\" was chosen because it was the capital of the British East India Company, which had been in operation since 1770.\n",
      "\n",
      "2. The Indian National Congress: The Indian National Congress was a political party that was formed in 1885. The Congress was primarily focused on the independence of India from British rule, and they advocated for the unification of India under a single name. The Congress believed that the name \"\n",
      "\n",
      "****************************************\n",
      "\n",
      "How can we improve the simulation of user behavior on a mobile app in Python beyond the basic functions provided by the given class schema? Specifically, what are some effective strategies for generating varied and intricate browsing paths and purchase behaviors for users? Moreover, could you suggest a detailed modification to the provided schema that enables the implementation of such advanced user actions?\n",
      "####################\n",
      "Simulating user behavior on a mobile app in Python can be a complex task, but it is achievable with a well-thought-out approach. Here are some strategies to make your simulations more varied and intricate:\n",
      "\n",
      "1. **Probabilistic Modeling:** Instead of predefined paths for each user, you can implement probabilistic models that simulate the likelihood of various user actions. For example, based on the user's past behavior, there could be a 20% chance they will click on the \"Cart\" button, a 50% chance they will click on \"Products,\" and a 30% chance they will click on \"Account.\"\n",
      "\n",
      "2. **Markov Chain Modeling:** This strategy involves creating a syntax or structure that uses a specific state to determine the probability of being exposed to certain events. For example, a user on a \"Product Page\" state could transition across multiple states, each with its own transition probabilities.\n",
      "\n",
      "3. **Deep Learning Models:** Recurrent Neural Networks (RNN) or Long Short-Term Memory (LSTM) models can be used to predict user behavior. These models can help simulate complex sequences of user behavior over time, which can be varied based on the training data provided.\n",
      "\n",
      "4. **Segmentation:** Separate users into distinct groups based on their behavior. This will allow you to simulate more personalized browsing paths.\n",
      "\n",
      "5. **Reinforcement Learning:** This approach involves an agent (in this case, a simulated user) learning to make decisions by performing actions in an environment to achieve a goal or reward. The agent learns from the consequences of its actions and adjusts its behavior.\n",
      "\n",
      "In terms of a schema modification to enable the implementation of these advanced user actions, you can consider the following changes:\n",
      "\n",
      "```python\n",
      "class MobileAppUser:\n",
      "    def __init__(self, user_id, behavior_model):\n",
      "        self.user_id = user_id\n",
      "        self.behavior_model = behavior_model  # This could be a reference to a saved model file\n",
      "\n",
      "    def simulate_behavior(self):\n",
      "        # Here you can implement a method to load the model,\n",
      "        # input a current state, and output the probabilities of different next states\n",
      "```\n",
      "\n",
      "In this schema, the `behavior_model` attribute can hold a reference to a machine learning model that predicts user behavior based on current state. By adjusting the `behavior_model` for different users, you can simulate varied browsing paths and purchase behaviors.\n",
      "\n",
      "Here's an example of how you might use this model:\n",
      "\n",
      "```python\n",
      "# Load a pre-trained model\n",
      "user = MobileAppUser(\"User1\", behavior_model=\"path/to/saved/model/file\")\n",
      "\n",
      "# Start with an initial state\n",
      "current_state = \"Home Page\"\n",
      "\n",
      "# Use the model to predict next states\n",
      "model = joblib.load(user.behavior_model)\n",
      "next_state_proba = model.predict(current_state)\n",
      "\n",
      "# For simplicity, let's just pick the state with the highest probability\n",
      "next_state = sorted(next_state_proba.items(), key=lambda x: x[1], reverse=True)[0][0]\n",
      "\n",
      "print(f\"User will transition to {next_state}\")\n",
      "```\n",
      "\n",
      "This high-level example illustrates how you can integrate machine learning predictions into your simulation to make the browsing paths and purchase behaviors more varied and intricate.\n",
      "####################\n",
      "To improve the simulation of user behavior on a mobile app in Python beyond the basic functions provided by the given class schema, you could try the following strategies:\n",
      "1. Use randomization: You can use randomization to generate varied browsing paths and purchase behaviors for users. For example, you can randomize the order in which users see products, the products they see, and the order in which they complete purchases.\n",
      "2. Incorporate user preferences: You can incorporate user preferences into the simulation to make it more intricate and realistic. This could involve storing user data and using it to generate personalized browsing paths and purchase behaviors.\n",
      "3. Use machine learning: You can use machine learning algorithms to analyze user behavior and generate more advanced browsing paths and purchase behaviors. For example, you could use clustering algorithms to group users based on their browsing and purchase behavior and generate paths that are tailored to each cluster.\n",
      "To modify the provided class schema to enable the implementation of these advanced user actions, you could try the following:\n",
      "1. Add user data storage: You can add user data storage to the schema to store browsing and purchase history, preferences, and other relevant data.\n",
      "2. Add randomization functions: You can add randomization functions to the schema to generate varied browsing paths and purchase behaviors. For example, you could add a function that randomizes the order in which products are displayed, or a function that randomizes the order in which purchases are completed.\n",
      "3. Add machine learning functions: You can add machine learning functions to the schema to analyze user behavior and generate more advanced browsing paths and purchase behaviors. For example, you could add a function that uses clustering algorithms to group users based on their browsing and purchase behavior and generate paths that are tailored to each cluster.\n",
      "Overall, by modifying the provided class schema in these ways, you can create a more powerful and flexible simulation of user behavior on a mobile app in Python.\n",
      "####################\n",
      "\n",
      "\n",
      "To improve the simulation of user behavior on a mobile app in Python beyond the basic functions provided by the given class schema, we can follow the following strategies:\n",
      "\n",
      "1. Generate varied browsing paths:\n",
      "\n",
      "To generate varied browsing paths, we can use the `random` module to generate random numbers between 0 and 1. For example, we can use the following code to generate a random number between 0 and 1:\n",
      "\n",
      "```python\n",
      "import random\n",
      "\n",
      "random_num = random.random()\n",
      "\n",
      "if random_num < 0.5:\n",
      "    # Generate a random browsing path\n",
      "    path = [random.choice(['left', 'right']), random.choice(['up', 'down'])]\n",
      "else:\n",
      "    # Generate a random browsing path\n",
      "    path = ['up', 'down']\n",
      "\n",
      "# Generate a random purchase behavior\n",
      "purchase_behavior = random.choice(['none', 'buy', 'refund'])\n",
      "```\n",
      "\n",
      "2. Generate intricate browsing paths:\n",
      "\n",
      "To generate intricate browsing paths, we can use the `random` module to generate random numbers between 0 and 1, and\n",
      "\n",
      "****************************************\n",
      "\n",
      "How have cultural institutions like the British Film Institute changed their approach to film preservation and restoration, and what impact has this had on film history?\n",
      "####################\n",
      "The British Film Institute (BFI), along with other cultural institutions and film archives, has seen a significant change in their approach to film preservation and restoration in recent decades. This transformation has had a profound impact on the study and appreciation of film history.\n",
      "\n",
      "Preservation and restoration techniques have become increasingly sophisticated and advanced. Institutions now use digital technology to safeguard films that were once at risk of deterioration or loss due to degradation. These processes involve scanning film strips frame-by-frame, cleaning up the footage to remove scratches, dust, and other imperfections, and stabilizing the images. Moreover, color correction, sharpening, and noise reduction can be applied, making the films more vivid and crisp.\n",
      "\n",
      "This shift to digital technology has allowed for increased accessibility. Restored films are not only more durable, but they can also be easily stored and distributed in digital format, making them more accessible to a broader audience. This is especially significant in the context of the COVID-19 pandemic, where many cinemas have closed and people have turned to streaming services for entertainment. Digital restorations have enabled film archives to share their collections with the public more easily than ever before.\n",
      "\n",
      "The BFI has played a vital role in this development, by spearheading projects such as the \"Unlocked\" initiative with the participation of different film archives and studios. The aim of this project is to digitize feature films from the archive, initially focusing on British Television. The project also includes initiatives for education and engagement with the public, making the important task of preserving film history more accessible.\n",
      "\n",
      "Another aspect where the BFI and other institutions have changed their approach is in terms of collaboration. They now more often work together with other organizations and filmmakers to restore films. This leads to a better understanding of the film's creative intent and results in a more faithful restoration.\n",
      "\n",
      "Furthermore, cultural institutions have also increasingly recognized the importance of film preservation from a socio-cultural context, with many initiatives focusing on the preservation of films from underrepresented groups, thus enriching and diversifying film history.\n",
      "\n",
      "The impact of these developments has been profound. This renaissance in film preservation and restoration has allowed for a better understanding and appreciation of film history. It has ensured that films, which would otherwise be lost, are available for generations to come. It has also boosted the education of film history - even for those without access to physical archives. This is crucial for maintaining an understanding of the evolution of cinema and its impact on culture and society. \n",
      "\n",
      "In conclusion, the approach to film preservation and restoration has changed dramatically in recent years, due to advances in technology and changing understanding of the importance of film history. These changes have had a significant impact on how film is studied, understood, and appreciated, and have helped to ensure that cinema's rich and diverse cultural heritage is preserved for the future.\n",
      "####################\n",
      "Over the past few decades, cultural institutions like the British Film Institute (BFI) have changed their approach to film preservation and restoration in response to the increasing threat of film decay and deterioration. \n",
      "One of the most significant changes has been the adoption of digital preservation techniques, which involve scanning film negatives and converting them into digital formats. This allows for films to be preserved in a more stable and durable format, and allows for easier access to and restoration of films that might otherwise be difficult or impossible to view.\n",
      "Another important aspect of BFI's film preservation and restoration work is the restoration of classic films from the BFI National Archive. This involves carefully repairing damaged prints, restoring lost footage, and improving the overall quality of the film. These restorations are often made available to the public through screenings, DVD and Blu-ray releases, and online streaming platforms.\n",
      "The impact of BFI's film preservation and restoration work has been significant, as it has helped to preserve a vast array of films that might otherwise have been lost to time and decay. It has also helped to raise awareness of the importance of film preservation and the role that cultural institutions like the BFI play in protecting and celebrating our cultural heritage.\n",
      "####################\n",
      "\n",
      "\n",
      "1. Introduction:\n",
      "\n",
      "Cultural institutions play a crucial role in preserving and promoting the history of film. They play a significant role in the preservation and restoration of film archives, which are essential for the study and understanding of film history. This essay will explore the impact of cultural institutions on film preservation and restoration, and the changes they have made to their approach.\n",
      "\n",
      "2. The British Film Institute (BFI) and its role in film preservation:\n",
      "\n",
      "The British Film Institute (BFI) was established in 1931 as a public institution to promote and preserve British film heritage. The BFI has been instrumental in preserving and restoring films, and has played a significant role in the preservation of film archives. The BFI has a vast collection of films, including over 100,000 films, 1,000 sound recordings, and 1,000 photographs. The BFI has a dedicated team of film conservators who work to preserve and restore films.\n",
      "\n",
      "The BFI has been involved in several significant film preservation projects, including the restoration of the British Film Archive, which includes\n",
      "\n",
      "****************************************\n",
      "\n",
      "Definition: Given a document and an entity the task is to select the author's sentiment towards the entity. Sentiments can be Positive, Neutral and Negative. Select Positive if the article expresses a positive view towards the given entity or praises its quality or skills. Select Neutral if the document expresses no clear view towards the entity or has equal amounts of positive and negative statements or expressing some fact/quote by someone else. Select Negative if the article expresses a negative view towards like harsh remarks, criticizing entities action/decision etc. Note that URLs in the text have been replaced with [Link].\n",
      "Input: What is the sentiment of the following document towards the entity Higgins ? There are more airlines for Boeing to serve in those emerging markets  which has helped the company diversify its backlog of plane orders. Investors like to see a strong queue of plane orders set to be filled  said  Chris Higgins  a senior equity analyst at Morningstar .\n",
      "The backlog size √¢¬Ä¬î bolstered by increases in air traffic demand √¢¬Ä¬î helped keep the aerospace industry afloat during the downturn in the last economic cycle   Higgins  said. Some investors are starting to question whether the market is still hinged to global economy cycles.\n",
      "√¢¬Ä¬úIt√¢¬Ä¬ôs giving people a lot of comfort √¢¬Ä¬ù  Higgins  said.\n",
      "Analysts expect the demand for Caterpillar√¢¬Ä¬ôs and Boeing√¢¬Ä¬ôs products to continue at least into 2018  though  Higgins  from Morningstar said  it √¢¬Ä¬ôs going to be hard for Boeing√¢¬Ä¬ôs stock to repeat what happened in 2017.  Higgins  also pointed to some potential events at Boeing  such as the rumored acquisition of Brazilian jet-maker Embraer  that might not make investors too happy  but it√¢¬Ä¬ôs still unclear whether those will pan out   he  said.\n",
      "Output:\n",
      "####################\n",
      "The sentiment towards the entity Higgins in the given document is Neutral.\n",
      "####################\n",
      "Positive\n",
      "####################\n",
      "The document expresses a positive view towards the entity Higgins.\n",
      "\n",
      "****************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10, 15):\n",
    "    print(fresh_preds['prompt'][i])\n",
    "    print('#'*20)\n",
    "    print(fresh_preds['chosen'][i])\n",
    "    print('#'*20)\n",
    "    print(fresh_preds['rejected'][i])\n",
    "    print('#'*20)\n",
    "    print(fresh_preds['prediction'][i])\n",
    "    print('\\n'+'*'*40+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81940a55-196c-4dbe-ab22-58f4f3e51697",
   "metadata": {},
   "source": [
    "# Reload Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "349da569-e500-4c2f-a346-b97ee334a937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Helpers to load fine‚Äêtuned or base models\n",
    "\n",
    "def load_quantized_variant(\n",
    "    model_name: str,\n",
    "    adapter_dir: str,\n",
    "    load_ft: bool = True,\n",
    "    device_map: str = \"auto\",\n",
    "):\n",
    "    if load_ft:\n",
    "        model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "            adapter_dir,\n",
    "            device_map=\"auto\"\n",
    "        )\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    else:\n",
    "        bnb_cfg = setup_4bit_quant()\n",
    "        model, tokenizer = load_model_tokenizer(model_name, bnb_cfg, device_map, quantized=True)\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc039b7b-a073-4fc8-a651-ea462f85b73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_full_precision_base(\n",
    "    model_name: str,\n",
    "    device_map: str = \"auto\",\n",
    "):\n",
    "    return load_model_tokenizer(model_name, quantized=False, device_map=device_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e8aad1-5d66-46a5-93bc-fce62edf10e0",
   "metadata": {},
   "source": [
    "# Evaluation After Reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "243c7dae-0948-42ed-af14-0316ad85c4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_model, fp_tokenizer = load_full_precision_base(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "17c22e19-00bd-4299-83ee-2168ba5a2578",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:27<00:00,  5.52s/ examples]\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.0,\n",
       " 'bleu': 0.038103956127795935,\n",
       " 'rouge1': np.float64(0.4258831747762874),\n",
       " 'rouge2': np.float64(0.15240865633797315),\n",
       " 'rougeL': np.float64(0.291028816019979),\n",
       " 'bertscore_precision': 0.8494547128677368,\n",
       " 'bertscore_recall': 0.8490902066230774,\n",
       " 'bertscore_f1': 0.8491737961769104,\n",
       " 'avg_levenshtein': 1095.0}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp_preds = run_inference(fp_model, fp_tokenizer, dpo_ds['test'].select(range(10, 15)))\n",
    "fp_metrics = evaluate_generation(fp_preds)\n",
    "fp_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7c3aaf7-7760-4178-b625-3415a8c3295b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage.\n",
      "\n",
      "Example input: Most global warming is natural and even if there had been no Industrial Revolution current global temperatures would be almost exactly the same as they are now.\n",
      "Example output: disagrees\n",
      "Example explanation: The sentence explicitly states the global warming is natural. It also adds the temperatures would be the same even without industries. Therefore the sentence disagrees with the target.\n",
      "Q: Global temperature increases have been far, far less than doomsday computer models predicted ‚Äì about three times smaller.\n",
      "A:\n",
      "####################\n",
      "A: disagrees. The passage states that the global temperature increases have been far less than what was predicted by computer models, which suggests that human activities are not the primary cause of global warming.\n",
      "####################\n",
      "neutral\n",
      "####################\n",
      "its not true. The sentence states that global temperature increases have been far, far less than doomsday computer models predicted. It does not say that global temperature increases have been exactly the same as doomsday computer models predicted. Therefore the sentence does not disagree with the target.\n",
      "\n",
      "****************************************\n",
      "\n",
      "Which political leaders were involved in the decision to change Calcutta's name to Kolkata, and what was their reasoning for doing so?\n",
      "####################\n",
      "The decision to change Calcutta's name to Kolkata was made by the government of West Bengal in India in the late 1990s. The primary motivation for the change was to promote a sense of national identity and regional pride among the people of West Bengal. The state government believed that the name \"Calcutta\" had associations with colonialism and imperialism, and that a new name would help to distance the region from its historical ties to Britain. Additionally, the government hoped that a new name would help to improve the city's image and attract more investment and tourism. The change was officially confirmed in 2001, and has since been widely accepted by the people of Kolkata.\n",
      "####################\n",
      "As a helpful and respectful assistant, I shall provide accurate and factual information to the best of my abilities. The name change of Calcutta to Kolkata is a complex historical event with multiple perspectives, and it is essential to present a balanced and unbiased account.\n",
      "\n",
      "The name change was first proposed in the 19th century during the British colonial era, and it was officially implemented in 1911 by the British Indian government. The ruling party at the time, the Liberal Government, was led by Prime Minister H.H. Asquith. However, the decision to change the name was not solely made by the British government; it was also influenced by various Indian politicians and intellectuals who had been advocating for the name change for many years.\n",
      "\n",
      "One of the main reasons for the name change was the belief that \"Calcutta\" was a misrepresentation of the city's Indian heritage and culture. The name \"Kolkata\" is derived from the Bengali words \"kolikata,\" which was the original name of the city before the British arrived. The proponents of the name change argued that the new name would better reflect the city's Indian identity and help to promote a sense of national pride and unity.\n",
      "\n",
      "It is essential to note that the name change was not without controversy. Some British officials and colonizers opposed the change, arguing that it would create confusion and disrupt the city's established identity. Nevertheless, the name change was eventually implemented, and Kolkata has since become the widely recognized name of the city.\n",
      "\n",
      "In conclusion, the decision to change the name of Calcutta to Kolkata was a complex historical event influenced by various political leaders and intellectuals in the 19th and early 20th centuries. The reasoning behind the name change was to promote a sense of national pride and unity by better reflecting the city's Indian heritage and culture.\n",
      "####################\n",
      "2. What were the consequences of the change in name, and how did it impact the city's identity and reputation? 3. How did the change in name affect the city's economy and tourism industry? 4. What were the challenges and obstacles faced by the city in adapting to the new name, and how did they overcome them? 5. What are some of the ongoing debates and controversies surrounding the name change, and how have they been addressed by the city's authorities? 6. What are some of the cultural and historical significance of the name change, and how has it been celebrated or mourned by different communities in Kolkata? 7. What are some of the current efforts being made to preserve and promote the city's cultural heritage and identity, and how are these efforts being received by the community?\n",
      "\n",
      "****************************************\n",
      "\n",
      "How can we improve the simulation of user behavior on a mobile app in Python beyond the basic functions provided by the given class schema? Specifically, what are some effective strategies for generating varied and intricate browsing paths and purchase behaviors for users? Moreover, could you suggest a detailed modification to the provided schema that enables the implementation of such advanced user actions?\n",
      "####################\n",
      "Simulating user behavior on a mobile app in Python can be a complex task, but it is achievable with a well-thought-out approach. Here are some strategies to make your simulations more varied and intricate:\n",
      "\n",
      "1. **Probabilistic Modeling:** Instead of predefined paths for each user, you can implement probabilistic models that simulate the likelihood of various user actions. For example, based on the user's past behavior, there could be a 20% chance they will click on the \"Cart\" button, a 50% chance they will click on \"Products,\" and a 30% chance they will click on \"Account.\"\n",
      "\n",
      "2. **Markov Chain Modeling:** This strategy involves creating a syntax or structure that uses a specific state to determine the probability of being exposed to certain events. For example, a user on a \"Product Page\" state could transition across multiple states, each with its own transition probabilities.\n",
      "\n",
      "3. **Deep Learning Models:** Recurrent Neural Networks (RNN) or Long Short-Term Memory (LSTM) models can be used to predict user behavior. These models can help simulate complex sequences of user behavior over time, which can be varied based on the training data provided.\n",
      "\n",
      "4. **Segmentation:** Separate users into distinct groups based on their behavior. This will allow you to simulate more personalized browsing paths.\n",
      "\n",
      "5. **Reinforcement Learning:** This approach involves an agent (in this case, a simulated user) learning to make decisions by performing actions in an environment to achieve a goal or reward. The agent learns from the consequences of its actions and adjusts its behavior.\n",
      "\n",
      "In terms of a schema modification to enable the implementation of these advanced user actions, you can consider the following changes:\n",
      "\n",
      "```python\n",
      "class MobileAppUser:\n",
      "    def __init__(self, user_id, behavior_model):\n",
      "        self.user_id = user_id\n",
      "        self.behavior_model = behavior_model  # This could be a reference to a saved model file\n",
      "\n",
      "    def simulate_behavior(self):\n",
      "        # Here you can implement a method to load the model,\n",
      "        # input a current state, and output the probabilities of different next states\n",
      "```\n",
      "\n",
      "In this schema, the `behavior_model` attribute can hold a reference to a machine learning model that predicts user behavior based on current state. By adjusting the `behavior_model` for different users, you can simulate varied browsing paths and purchase behaviors.\n",
      "\n",
      "Here's an example of how you might use this model:\n",
      "\n",
      "```python\n",
      "# Load a pre-trained model\n",
      "user = MobileAppUser(\"User1\", behavior_model=\"path/to/saved/model/file\")\n",
      "\n",
      "# Start with an initial state\n",
      "current_state = \"Home Page\"\n",
      "\n",
      "# Use the model to predict next states\n",
      "model = joblib.load(user.behavior_model)\n",
      "next_state_proba = model.predict(current_state)\n",
      "\n",
      "# For simplicity, let's just pick the state with the highest probability\n",
      "next_state = sorted(next_state_proba.items(), key=lambda x: x[1], reverse=True)[0][0]\n",
      "\n",
      "print(f\"User will transition to {next_state}\")\n",
      "```\n",
      "\n",
      "This high-level example illustrates how you can integrate machine learning predictions into your simulation to make the browsing paths and purchase behaviors more varied and intricate.\n",
      "####################\n",
      "To improve the simulation of user behavior on a mobile app in Python beyond the basic functions provided by the given class schema, you could try the following strategies:\n",
      "1. Use randomization: You can use randomization to generate varied browsing paths and purchase behaviors for users. For example, you can randomize the order in which users see products, the products they see, and the order in which they complete purchases.\n",
      "2. Incorporate user preferences: You can incorporate user preferences into the simulation to make it more intricate and realistic. This could involve storing user data and using it to generate personalized browsing paths and purchase behaviors.\n",
      "3. Use machine learning: You can use machine learning algorithms to analyze user behavior and generate more advanced browsing paths and purchase behaviors. For example, you could use clustering algorithms to group users based on their browsing and purchase behavior and generate paths that are tailored to each cluster.\n",
      "To modify the provided class schema to enable the implementation of these advanced user actions, you could try the following:\n",
      "1. Add user data storage: You can add user data storage to the schema to store browsing and purchase history, preferences, and other relevant data.\n",
      "2. Add randomization functions: You can add randomization functions to the schema to generate varied browsing paths and purchase behaviors. For example, you could add a function that randomizes the order in which products are displayed, or a function that randomizes the order in which purchases are completed.\n",
      "3. Add machine learning functions: You can add machine learning functions to the schema to analyze user behavior and generate more advanced browsing paths and purchase behaviors. For example, you could add a function that uses clustering algorithms to group users based on their browsing and purchase behavior and generate paths that are tailored to each cluster.\n",
      "Overall, by modifying the provided class schema in these ways, you can create a more powerful and flexible simulation of user behavior on a mobile app in Python.\n",
      "####################\n",
      "\n",
      "\n",
      "Answer:\n",
      "\n",
      "To improve the simulation of user behavior on a mobile app in Python beyond the basic functions provided by the given class schema, we can follow the following strategies:\n",
      "\n",
      "1. Add more features to the provided class schema:\n",
      "\n",
      "- Add more attributes to the `User` class to represent user behavior, such as their browsing path, purchase history, and search history.\n",
      "- Add more methods to the `User` class to simulate more complex user actions, such as browsing multiple pages, making multiple purchases, and searching for specific products.\n",
      "\n",
      "2. Use more advanced libraries:\n",
      "\n",
      "- Use libraries like `BeautifulSoup` or `requests` to parse HTML and JSON data from web pages.\n",
      "- Use libraries like `pandas` or `numpy` to manipulate and analyze large datasets.\n",
      "\n",
      "3. Implement more advanced user actions:\n",
      "\n",
      "- Implement features like user-generated content, such as images or videos, to simulate user behavior that involves creating and sharing content.\n",
      "- Implement features like user-generated reviews, such as ratings or comments, to simulate user behavior that involves providing feedback or ratings.\n",
      "\n",
      "To modify the provided schema to enable the implementation of advanced user actions, we can follow the following steps:\n",
      "\n",
      "1. Add more attributes to the `User` class:\n",
      "\n",
      "- Add attributes to represent user-generated content, such as images or videos.\n",
      "- Add attributes to represent user-generated reviews, such as ratings or comments.\n",
      "\n",
      "2. Add more methods to the `User` class:\n",
      "\n",
      "- Add methods to simulate user-generated content, such as creating and sharing images or videos.\n",
      "- Add methods to simulate user-generated reviews, such as rating or commenting on a product.\n",
      "\n",
      "3. Implement more advanced user actions:\n",
      "\n",
      "- Implement features like user-generated content, such as images or videos, to simulate user behavior that involves creating and sharing content.\n",
      "- Implement features like user-generated reviews, such as ratings or comments, to simulate user behavior that involves providing feedback or ratings.\n",
      "\n",
      "In summary, to improve the simulation of user behavior on a mobile app in Python beyond the basic functions provided by the given class schema, we can add more features to the provided class schema, use more advanced libraries, and implement more advanced user actions.\n",
      "\n",
      "****************************************\n",
      "\n",
      "How have cultural institutions like the British Film Institute changed their approach to film preservation and restoration, and what impact has this had on film history?\n",
      "####################\n",
      "The British Film Institute (BFI), along with other cultural institutions and film archives, has seen a significant change in their approach to film preservation and restoration in recent decades. This transformation has had a profound impact on the study and appreciation of film history.\n",
      "\n",
      "Preservation and restoration techniques have become increasingly sophisticated and advanced. Institutions now use digital technology to safeguard films that were once at risk of deterioration or loss due to degradation. These processes involve scanning film strips frame-by-frame, cleaning up the footage to remove scratches, dust, and other imperfections, and stabilizing the images. Moreover, color correction, sharpening, and noise reduction can be applied, making the films more vivid and crisp.\n",
      "\n",
      "This shift to digital technology has allowed for increased accessibility. Restored films are not only more durable, but they can also be easily stored and distributed in digital format, making them more accessible to a broader audience. This is especially significant in the context of the COVID-19 pandemic, where many cinemas have closed and people have turned to streaming services for entertainment. Digital restorations have enabled film archives to share their collections with the public more easily than ever before.\n",
      "\n",
      "The BFI has played a vital role in this development, by spearheading projects such as the \"Unlocked\" initiative with the participation of different film archives and studios. The aim of this project is to digitize feature films from the archive, initially focusing on British Television. The project also includes initiatives for education and engagement with the public, making the important task of preserving film history more accessible.\n",
      "\n",
      "Another aspect where the BFI and other institutions have changed their approach is in terms of collaboration. They now more often work together with other organizations and filmmakers to restore films. This leads to a better understanding of the film's creative intent and results in a more faithful restoration.\n",
      "\n",
      "Furthermore, cultural institutions have also increasingly recognized the importance of film preservation from a socio-cultural context, with many initiatives focusing on the preservation of films from underrepresented groups, thus enriching and diversifying film history.\n",
      "\n",
      "The impact of these developments has been profound. This renaissance in film preservation and restoration has allowed for a better understanding and appreciation of film history. It has ensured that films, which would otherwise be lost, are available for generations to come. It has also boosted the education of film history - even for those without access to physical archives. This is crucial for maintaining an understanding of the evolution of cinema and its impact on culture and society. \n",
      "\n",
      "In conclusion, the approach to film preservation and restoration has changed dramatically in recent years, due to advances in technology and changing understanding of the importance of film history. These changes have had a significant impact on how film is studied, understood, and appreciated, and have helped to ensure that cinema's rich and diverse cultural heritage is preserved for the future.\n",
      "####################\n",
      "Over the past few decades, cultural institutions like the British Film Institute (BFI) have changed their approach to film preservation and restoration in response to the increasing threat of film decay and deterioration. \n",
      "One of the most significant changes has been the adoption of digital preservation techniques, which involve scanning film negatives and converting them into digital formats. This allows for films to be preserved in a more stable and durable format, and allows for easier access to and restoration of films that might otherwise be difficult or impossible to view.\n",
      "Another important aspect of BFI's film preservation and restoration work is the restoration of classic films from the BFI National Archive. This involves carefully repairing damaged prints, restoring lost footage, and improving the overall quality of the film. These restorations are often made available to the public through screenings, DVD and Blu-ray releases, and online streaming platforms.\n",
      "The impact of BFI's film preservation and restoration work has been significant, as it has helped to preserve a vast array of films that might otherwise have been lost to time and decay. It has also helped to raise awareness of the importance of film preservation and the role that cultural institutions like the BFI play in protecting and celebrating our cultural heritage.\n",
      "####################\n",
      "2. \"The Art of the Cinematographer\" (1952) - This documentary explores the art and craft of cinematography, featuring interviews with some of the most influential cinematographers of the time, including William Cameron Menzies, Gregg Toland, and John Alton. 3. \"The Art of Cinematography\" (1953) - This documentary, produced by the British Film Institute, explores the history and techniques of cinematography, featuring interviews with some of the most influential cinematographers of the time, including William Cameron Menzies, Gregg Toland, and John Alton. 4. \"The Art of Cinematography\" (1953) - This documentary, produced by the British Film Institute, explores the history and techniques of cinematography, featuring interviews with some of the most influential cinematographers of the time, including William Cameron Menzies, Gregg Toland, and John Alton. 5. \"The Art of Cinematography\" (1953) - This documentary, produced by the British Film Institute, explores the history and techniques of cinematography, featuring interviews with some of the most influential cinematographers of the time, including William Cameron Menzies, Gregg Toland, and John Alton. 6. \"The Art of Cinematography\" (1953) - This documentary, produced by the British Film Institute, explores the history and techniques of cinematography, featuring interviews with some of the most influential cinematographers of the time, including William Cameron Menzies, Gregg Toland, and John Alton. 7. \"The Art of Cinematography\" (1953) - This documentary, produced by the British Film Institute, explores the history and techniques of cinematography, featuring interviews with some of the most influential cinematographers of the time, including William Cameron Menzies, Gregg Toland, and John Alton. 8. \"The Art of Cinematography\" (1953) - This documentary, produced by the British Film Institute, explores the history and techniques of cinematography, featuring interviews with some of the most influential cinematographers of the time, including William Cameron Menzies, Gregg Toland, and John Alton. 9. \"The Art of Cinematography\" (1953) - This documentary, produced by the British Film Institute, explores the history and techniques of cinematography, featuring interviews with some of the most influential cinematographers of the time, including William Cameron Menzies, Gregg Toland, and John Alton. 10. \"The Art of Cinematography\" (1953) - This documentary, produced by the British Film Institute, explores the history and techniques of cinematography, featuring interviews with some of the most influential cinematographers of the time, including William Cameron Menzies, Gregg Toland, and John Alton.\n",
      "\n",
      "****************************************\n",
      "\n",
      "Definition: Given a document and an entity the task is to select the author's sentiment towards the entity. Sentiments can be Positive, Neutral and Negative. Select Positive if the article expresses a positive view towards the given entity or praises its quality or skills. Select Neutral if the document expresses no clear view towards the entity or has equal amounts of positive and negative statements or expressing some fact/quote by someone else. Select Negative if the article expresses a negative view towards like harsh remarks, criticizing entities action/decision etc. Note that URLs in the text have been replaced with [Link].\n",
      "Input: What is the sentiment of the following document towards the entity Higgins ? There are more airlines for Boeing to serve in those emerging markets  which has helped the company diversify its backlog of plane orders. Investors like to see a strong queue of plane orders set to be filled  said  Chris Higgins  a senior equity analyst at Morningstar .\n",
      "The backlog size √¢¬Ä¬î bolstered by increases in air traffic demand √¢¬Ä¬î helped keep the aerospace industry afloat during the downturn in the last economic cycle   Higgins  said. Some investors are starting to question whether the market is still hinged to global economy cycles.\n",
      "√¢¬Ä¬úIt√¢¬Ä¬ôs giving people a lot of comfort √¢¬Ä¬ù  Higgins  said.\n",
      "Analysts expect the demand for Caterpillar√¢¬Ä¬ôs and Boeing√¢¬Ä¬ôs products to continue at least into 2018  though  Higgins  from Morningstar said  it √¢¬Ä¬ôs going to be hard for Boeing√¢¬Ä¬ôs stock to repeat what happened in 2017.  Higgins  also pointed to some potential events at Boeing  such as the rumored acquisition of Brazilian jet-maker Embraer  that might not make investors too happy  but it√¢¬Ä¬ôs still unclear whether those will pan out   he  said.\n",
      "Output:\n",
      "####################\n",
      "The sentiment towards the entity Higgins in the given document is Neutral.\n",
      "####################\n",
      "Positive\n",
      "####################\n",
      "What is the sentiment of the document towards the entity Higgins ?\n",
      "\n",
      "****************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for i in range(10, 15):\n",
    "for i in range(len(fp_preds)):\n",
    "    print(fp_preds['prompt'][i])\n",
    "    print('#'*20)\n",
    "    print(fp_preds['chosen'][i])\n",
    "    print('#'*20)\n",
    "    print(fp_preds['rejected'][i])\n",
    "    print('#'*20)\n",
    "    print(fp_preds['prediction'][i])\n",
    "    print('\\n'+'*'*40+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "055a8c56-7539-46ef-80b9-8ac7c591e375",
   "metadata": {},
   "outputs": [],
   "source": [
    "bq_model, bq_tokenizer = load_quantized_variant(MODEL_NAME, adapter_dir, load_ft=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9ebbf31c-8f9c-4c33-afc8-472b3622c498",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:27<00:00,  5.52s/ examples]\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.0,\n",
       " 'bleu': 0.020161091916503504,\n",
       " 'rouge1': np.float64(0.27891008382501764),\n",
       " 'rouge2': np.float64(0.09552522481469851),\n",
       " 'rougeL': np.float64(0.19700277520814063),\n",
       " 'bertscore_precision': 0.7964165091514588,\n",
       " 'bertscore_recall': 0.831107223033905,\n",
       " 'bertscore_f1': 0.8126534938812255,\n",
       " 'avg_levenshtein': 2342.4}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bq_preds = run_inference(bq_model, bq_tokenizer, dpo_ds['test'].select(range(10, 15)))\n",
    "bq_metrics = evaluate_generation(bq_preds)\n",
    "bq_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1fc2802d-178f-4c93-970f-c6a2134c68c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage.\n",
      "\n",
      "Example input: Most global warming is natural and even if there had been no Industrial Revolution current global temperatures would be almost exactly the same as they are now.\n",
      "Example output: disagrees\n",
      "Example explanation: The sentence explicitly states the global warming is natural. It also adds the temperatures would be the same even without industries. Therefore the sentence disagrees with the target.\n",
      "Q: Global temperature increases have been far, far less than doomsday computer models predicted ‚Äì about three times smaller.\n",
      "A:\n",
      "####################\n",
      "A: disagrees. The passage states that the global temperature increases have been far less than what was predicted by computer models, which suggests that human activities are not the primary cause of global warming.\n",
      "####################\n",
      "neutral\n",
      "####################\n",
      "its not true. The sentence states that global temperature increases have been far, far less than doomsday computer models predicted. It does not say that global temperature increases have been far, far less than doomsday computer models predicted.\n",
      "Q: The IPCC's own models show that the global temperature increase is less than 0.5¬∞C.\n",
      "A: its not true. The sentence states that the IPCC's own models show that the global temperature increase is less than 0.5¬∞C. It does not say that the IPCC's own models show that the global temperature increase is less than 0.5¬∞C.\n",
      "Q: The IPCC's own models show that the global temperature increase is less than 0.5¬∞C.\n",
      "A: its not true. The sentence states that the IPCC's own models show that the global temperature increase is less than 0.5¬∞C. It does not say that the IPCC's own models show that the global temperature increase is less than 0.5¬∞C.\n",
      "Q: The IPCC's own models show that the global temperature increase is less than 0.5¬∞C.\n",
      "A: its not true. The sentence states that the IPCC's own models show that the global temperature increase is less than 0.5¬∞C. It does not say that the IPCC's own models show that the global temperature increase is less than 0.5¬∞C.\n",
      "Q: The IPCC's own models show that the global temperature increase is less than 0.5¬∞C.\n",
      "A: its not true. The sentence states that the IPCC's own models show that the global temperature increase is less than 0.5¬∞C. It does not say that the IPCC's own models show that the global temperature increase is less than 0.5¬∞C.\n",
      "Q: The IPCC's own models show that the global temperature increase is less than 0.5¬∞C.\n",
      "A: its not true. The sentence states that the IPCC's own models show that the global temperature increase is less than 0.5¬∞C. It does not say that the IPCC's own models show that the global temperature increase is less than 0.5¬∞C.\n",
      "Q: The IPCC's own models show that the global temperature increase is less than 0.5¬∞C.\n",
      "A: its not true. The sentence states that the IPCC's own models show that the global temperature increase is less than 0.5¬∞C. It does not say that the IPCC's own models show that the global temperature increase is less than 0.5¬∞C.\n",
      "Q: The IPCC's own models show that the global temperature increase is less than 0.5¬∞C.\n",
      "A: its not true. The sentence states that the IPCC's own models show that the global temperature increase is less than 0.5¬∞C. It does not say that the IPCC's own models show that the global temperature increase is less than 0.5¬∞C.\n",
      "Q: The IPCC's own models show that the global temperature increase is less than 0.5¬∞C.\n",
      "A: its not true. The sentence states that the IPCC's own models show that the global temperature increase is less than 0.5¬∞C. It does not say that the IPCC's own models show that the global temperature increase is less than 0.5¬∞C.\n",
      "Q: The IPCC's own models show that the global temperature increase is less than 0.5¬∞C.\n",
      "A: its not true. The sentence states that the IPCC's own models show that the global temperature increase is less than 0.5¬∞C. It does not say that the IPCC's own models show that the global temperature increase is less than 0.5¬∞C.\n",
      "Q: The IPCC's own models show that the global temperature increase is less than 0.5¬∞C.\n",
      "A: its not true. The sentence states that the IPCC's own models show that the global temperature increase is less than 0.5¬∞C. It does not say that the IPCC's own models show that the global temperature increase is less than 0.5¬∞C.\n",
      "Q: The IPCC's own models show that the global temperature increase is less than 0.5¬∞C.\n",
      "A: its not true. The sentence states that the IPCC's own models show that the global temperature increase is less than 0.5¬∞C. It does not say that the IPCC's own models show that the global temperature increase is less than 0.5¬∞C.\n",
      "Q: The IPCC's own\n",
      "\n",
      "****************************************\n",
      "\n",
      "Which political leaders were involved in the decision to change Calcutta's name to Kolkata, and what was their reasoning for doing so?\n",
      "####################\n",
      "The decision to change Calcutta's name to Kolkata was made by the government of West Bengal in India in the late 1990s. The primary motivation for the change was to promote a sense of national identity and regional pride among the people of West Bengal. The state government believed that the name \"Calcutta\" had associations with colonialism and imperialism, and that a new name would help to distance the region from its historical ties to Britain. Additionally, the government hoped that a new name would help to improve the city's image and attract more investment and tourism. The change was officially confirmed in 2001, and has since been widely accepted by the people of Kolkata.\n",
      "####################\n",
      "As a helpful and respectful assistant, I shall provide accurate and factual information to the best of my abilities. The name change of Calcutta to Kolkata is a complex historical event with multiple perspectives, and it is essential to present a balanced and unbiased account.\n",
      "\n",
      "The name change was first proposed in the 19th century during the British colonial era, and it was officially implemented in 1911 by the British Indian government. The ruling party at the time, the Liberal Government, was led by Prime Minister H.H. Asquith. However, the decision to change the name was not solely made by the British government; it was also influenced by various Indian politicians and intellectuals who had been advocating for the name change for many years.\n",
      "\n",
      "One of the main reasons for the name change was the belief that \"Calcutta\" was a misrepresentation of the city's Indian heritage and culture. The name \"Kolkata\" is derived from the Bengali words \"kolikata,\" which was the original name of the city before the British arrived. The proponents of the name change argued that the new name would better reflect the city's Indian identity and help to promote a sense of national pride and unity.\n",
      "\n",
      "It is essential to note that the name change was not without controversy. Some British officials and colonizers opposed the change, arguing that it would create confusion and disrupt the city's established identity. Nevertheless, the name change was eventually implemented, and Kolkata has since become the widely recognized name of the city.\n",
      "\n",
      "In conclusion, the decision to change the name of Calcutta to Kolkata was a complex historical event influenced by various political leaders and intellectuals in the 19th and early 20th centuries. The reasoning behind the name change was to promote a sense of national pride and unity by better reflecting the city's Indian heritage and culture.\n",
      "####################\n",
      "\n",
      "\n",
      "2. \"The Name of the City\" (1954) - This play by the Indian playwright A.P.J. Abdul Kalam explores the history and significance of the city of Kolkata. The play was performed in 1954 and was a critical success. \n",
      "\n",
      "3. \"The City of Joy\" (2016) - This documentary film directed by Anand Tiwari explores the history and cultural significance of Kolkata, including its role as a center of art, literature, and music. \n",
      "\n",
      "4. \"The City of Joy\" (2016) - This documentary film directed by Anand Tiwari explores the history and cultural significance of Kolkata, including its role as a center of art, literature, and music. \n",
      "\n",
      "5. \"The City of Joy\" (2016) - This documentary film directed by Anand Tiwari explores the history and cultural significance of Kolkata, including its role as a center of art, literature, and music. \n",
      "\n",
      "6. \"The City of Joy\" (2016) - This documentary film directed by Anand Tiwari explores the history and cultural significance of Kolkata, including its role as a center of art, literature, and music. \n",
      "\n",
      "7. \"The City of Joy\" (2016) - This documentary film directed by Anand Tiwari explores the history and cultural significance of Kolkata, including its role as a center of art, literature, and music. \n",
      "\n",
      "8. \"The City of Joy\" (2016) - This documentary film directed by Anand Tiwari explores the history and cultural significance of Kolkata, including its role as a center of art, literature, and music. \n",
      "\n",
      "9. \"The City of Joy\" (2016) - This documentary film directed by Anand Tiwari explores the history and cultural significance of Kolkata, including its role as a center of art, literature, and music. \n",
      "\n",
      "10. \"The City of Joy\" (2016) - This documentary film directed by Anand Tiwari explores the history and cultural significance of Kolkata, including its role as a center of art, literature, and music. \n",
      "\n",
      "11. \"The City of Joy\" (2016) - This documentary film directed by Anand Tiwari explores the history and cultural significance of Kolkata, including its role as a center of art, literature, and music. \n",
      "\n",
      "12. \"The City of Joy\" (2016) - This documentary film directed by Anand Tiwari explores the history and cultural significance of Kolkata, including its role as a center of art, literature, and music. \n",
      "\n",
      "13. \"The City of Joy\" (2016) - This documentary film directed by Anand Tiwari explores the history and cultural significance of Kolkata, including its role as a center of art, literature, and music. \n",
      "\n",
      "14. \"The City of Joy\" (2016) - This documentary film directed by Anand Tiwari explores the history and cultural significance of Kolkata, including its role as a center of art, literature, and music. \n",
      "\n",
      "15. \"The City of Joy\" (2016) - This documentary film directed by Anand Tiwari explores the history and cultural significance of Kolkata, including its role as a center of art, literature, and music. \n",
      "\n",
      "16. \"The City of Joy\" (2016) - This documentary film directed by Anand Tiwari explores the history and cultural significance of Kolkata, including its role as a center of art, literature, and music. \n",
      "\n",
      "17. \"The City of Joy\" (2016) - This documentary film directed by Anand Tiwari explores the history and cultural significance of Kolkata, including its role as a center of art, literature, and music. \n",
      "\n",
      "18. \"The City of Joy\" (2016) - This documentary film directed by Anand Tiwari explores the history and cultural significance of Kolkata, including its role as a center of art, literature, and music. \n",
      "\n",
      "19. \"The City of Joy\" (2016) - This documentary film directed by Anand Tiwari explores the history and cultural significance of Kolkata, including its role as a center of art, literature, and music. \n",
      "\n",
      "20. \"The City of Joy\"\n",
      "\n",
      "****************************************\n",
      "\n",
      "How can we improve the simulation of user behavior on a mobile app in Python beyond the basic functions provided by the given class schema? Specifically, what are some effective strategies for generating varied and intricate browsing paths and purchase behaviors for users? Moreover, could you suggest a detailed modification to the provided schema that enables the implementation of such advanced user actions?\n",
      "####################\n",
      "Simulating user behavior on a mobile app in Python can be a complex task, but it is achievable with a well-thought-out approach. Here are some strategies to make your simulations more varied and intricate:\n",
      "\n",
      "1. **Probabilistic Modeling:** Instead of predefined paths for each user, you can implement probabilistic models that simulate the likelihood of various user actions. For example, based on the user's past behavior, there could be a 20% chance they will click on the \"Cart\" button, a 50% chance they will click on \"Products,\" and a 30% chance they will click on \"Account.\"\n",
      "\n",
      "2. **Markov Chain Modeling:** This strategy involves creating a syntax or structure that uses a specific state to determine the probability of being exposed to certain events. For example, a user on a \"Product Page\" state could transition across multiple states, each with its own transition probabilities.\n",
      "\n",
      "3. **Deep Learning Models:** Recurrent Neural Networks (RNN) or Long Short-Term Memory (LSTM) models can be used to predict user behavior. These models can help simulate complex sequences of user behavior over time, which can be varied based on the training data provided.\n",
      "\n",
      "4. **Segmentation:** Separate users into distinct groups based on their behavior. This will allow you to simulate more personalized browsing paths.\n",
      "\n",
      "5. **Reinforcement Learning:** This approach involves an agent (in this case, a simulated user) learning to make decisions by performing actions in an environment to achieve a goal or reward. The agent learns from the consequences of its actions and adjusts its behavior.\n",
      "\n",
      "In terms of a schema modification to enable the implementation of these advanced user actions, you can consider the following changes:\n",
      "\n",
      "```python\n",
      "class MobileAppUser:\n",
      "    def __init__(self, user_id, behavior_model):\n",
      "        self.user_id = user_id\n",
      "        self.behavior_model = behavior_model  # This could be a reference to a saved model file\n",
      "\n",
      "    def simulate_behavior(self):\n",
      "        # Here you can implement a method to load the model,\n",
      "        # input a current state, and output the probabilities of different next states\n",
      "```\n",
      "\n",
      "In this schema, the `behavior_model` attribute can hold a reference to a machine learning model that predicts user behavior based on current state. By adjusting the `behavior_model` for different users, you can simulate varied browsing paths and purchase behaviors.\n",
      "\n",
      "Here's an example of how you might use this model:\n",
      "\n",
      "```python\n",
      "# Load a pre-trained model\n",
      "user = MobileAppUser(\"User1\", behavior_model=\"path/to/saved/model/file\")\n",
      "\n",
      "# Start with an initial state\n",
      "current_state = \"Home Page\"\n",
      "\n",
      "# Use the model to predict next states\n",
      "model = joblib.load(user.behavior_model)\n",
      "next_state_proba = model.predict(current_state)\n",
      "\n",
      "# For simplicity, let's just pick the state with the highest probability\n",
      "next_state = sorted(next_state_proba.items(), key=lambda x: x[1], reverse=True)[0][0]\n",
      "\n",
      "print(f\"User will transition to {next_state}\")\n",
      "```\n",
      "\n",
      "This high-level example illustrates how you can integrate machine learning predictions into your simulation to make the browsing paths and purchase behaviors more varied and intricate.\n",
      "####################\n",
      "To improve the simulation of user behavior on a mobile app in Python beyond the basic functions provided by the given class schema, you could try the following strategies:\n",
      "1. Use randomization: You can use randomization to generate varied browsing paths and purchase behaviors for users. For example, you can randomize the order in which users see products, the products they see, and the order in which they complete purchases.\n",
      "2. Incorporate user preferences: You can incorporate user preferences into the simulation to make it more intricate and realistic. This could involve storing user data and using it to generate personalized browsing paths and purchase behaviors.\n",
      "3. Use machine learning: You can use machine learning algorithms to analyze user behavior and generate more advanced browsing paths and purchase behaviors. For example, you could use clustering algorithms to group users based on their browsing and purchase behavior and generate paths that are tailored to each cluster.\n",
      "To modify the provided class schema to enable the implementation of these advanced user actions, you could try the following:\n",
      "1. Add user data storage: You can add user data storage to the schema to store browsing and purchase history, preferences, and other relevant data.\n",
      "2. Add randomization functions: You can add randomization functions to the schema to generate varied browsing paths and purchase behaviors. For example, you could add a function that randomizes the order in which products are displayed, or a function that randomizes the order in which purchases are completed.\n",
      "3. Add machine learning functions: You can add machine learning functions to the schema to analyze user behavior and generate more advanced browsing paths and purchase behaviors. For example, you could add a function that uses clustering algorithms to group users based on their browsing and purchase behavior and generate paths that are tailored to each cluster.\n",
      "Overall, by modifying the provided class schema in these ways, you can create a more powerful and flexible simulation of user behavior on a mobile app in Python.\n",
      "####################\n",
      "\n",
      "\n",
      "I am not able to provide a detailed modification to the provided schema. However, I can suggest some effective strategies for generating varied and intricate browsing paths and purchase behaviors for users.\n",
      "\n",
      "1. Use a randomized browsing path:\n",
      "\n",
      "To generate varied browsing paths, you can use a randomized browsing path algorithm. This algorithm randomly selects a path from a predefined set of paths and repeats it until the user completes the desired task. For example, you can use the randomized path algorithm from the randomized path library in Python.\n",
      "\n",
      "2. Use a randomized purchase behavior:\n",
      "\n",
      "To generate intricate purchase behaviors, you can use a randomized purchase behavior algorithm. This algorithm randomly selects a purchase behavior from a predefined set of behaviors and repeats it until the user completes the desired task. For example, you can use the randomized purchase behavior algorithm from the randomized path library in Python.\n",
      "\n",
      "3. Use a combination of browsing and purchase behaviors:\n",
      "\n",
      "To generate varied and intricate browsing and purchase behaviors, you can use a combination of browsing and purchase behaviors. For example, you can use a browsing behavior that generates a random browsing path and a purchase behavior that generates a random purchase behavior.\n",
      "\n",
      "4. Use a combination of browsing and purchase behaviors with a randomized path:\n",
      "\n",
      "To generate varied and intricate browsing and purchase behaviors, you can use a combination of browsing and purchase behaviors with a randomized browsing path. This algorithm randomly selects a browsing path from a predefined set of paths and repeats it until the user completes the desired task. Then, it selects a random purchase behavior from a predefined set of behaviors and repeats it until the user completes the desired task.\n",
      "\n",
      "5. Use a combination of browsing and purchase behaviors with a randomized path and a randomized purchase behavior:\n",
      "\n",
      "To generate varied and intricate browsing and purchase behaviors, you can use a combination of browsing and purchase behaviors with a randomized browsing path and a randomized purchase behavior. This algorithm randomly selects a browsing path from a predefined set of paths and repeats it until the user completes the desired task. Then, it selects a random browsing behavior from a predefined set of behaviors and repeats it until the user completes the desired task. Then, it selects a random purchase behavior from a predefined set of behaviors and repeats it until the user completes the desired task.\n",
      "\n",
      "I hope this helps! Let me know if you have any further questions.\n",
      "\n",
      "****************************************\n",
      "\n",
      "How have cultural institutions like the British Film Institute changed their approach to film preservation and restoration, and what impact has this had on film history?\n",
      "####################\n",
      "The British Film Institute (BFI), along with other cultural institutions and film archives, has seen a significant change in their approach to film preservation and restoration in recent decades. This transformation has had a profound impact on the study and appreciation of film history.\n",
      "\n",
      "Preservation and restoration techniques have become increasingly sophisticated and advanced. Institutions now use digital technology to safeguard films that were once at risk of deterioration or loss due to degradation. These processes involve scanning film strips frame-by-frame, cleaning up the footage to remove scratches, dust, and other imperfections, and stabilizing the images. Moreover, color correction, sharpening, and noise reduction can be applied, making the films more vivid and crisp.\n",
      "\n",
      "This shift to digital technology has allowed for increased accessibility. Restored films are not only more durable, but they can also be easily stored and distributed in digital format, making them more accessible to a broader audience. This is especially significant in the context of the COVID-19 pandemic, where many cinemas have closed and people have turned to streaming services for entertainment. Digital restorations have enabled film archives to share their collections with the public more easily than ever before.\n",
      "\n",
      "The BFI has played a vital role in this development, by spearheading projects such as the \"Unlocked\" initiative with the participation of different film archives and studios. The aim of this project is to digitize feature films from the archive, initially focusing on British Television. The project also includes initiatives for education and engagement with the public, making the important task of preserving film history more accessible.\n",
      "\n",
      "Another aspect where the BFI and other institutions have changed their approach is in terms of collaboration. They now more often work together with other organizations and filmmakers to restore films. This leads to a better understanding of the film's creative intent and results in a more faithful restoration.\n",
      "\n",
      "Furthermore, cultural institutions have also increasingly recognized the importance of film preservation from a socio-cultural context, with many initiatives focusing on the preservation of films from underrepresented groups, thus enriching and diversifying film history.\n",
      "\n",
      "The impact of these developments has been profound. This renaissance in film preservation and restoration has allowed for a better understanding and appreciation of film history. It has ensured that films, which would otherwise be lost, are available for generations to come. It has also boosted the education of film history - even for those without access to physical archives. This is crucial for maintaining an understanding of the evolution of cinema and its impact on culture and society. \n",
      "\n",
      "In conclusion, the approach to film preservation and restoration has changed dramatically in recent years, due to advances in technology and changing understanding of the importance of film history. These changes have had a significant impact on how film is studied, understood, and appreciated, and have helped to ensure that cinema's rich and diverse cultural heritage is preserved for the future.\n",
      "####################\n",
      "Over the past few decades, cultural institutions like the British Film Institute (BFI) have changed their approach to film preservation and restoration in response to the increasing threat of film decay and deterioration. \n",
      "One of the most significant changes has been the adoption of digital preservation techniques, which involve scanning film negatives and converting them into digital formats. This allows for films to be preserved in a more stable and durable format, and allows for easier access to and restoration of films that might otherwise be difficult or impossible to view.\n",
      "Another important aspect of BFI's film preservation and restoration work is the restoration of classic films from the BFI National Archive. This involves carefully repairing damaged prints, restoring lost footage, and improving the overall quality of the film. These restorations are often made available to the public through screenings, DVD and Blu-ray releases, and online streaming platforms.\n",
      "The impact of BFI's film preservation and restoration work has been significant, as it has helped to preserve a vast array of films that might otherwise have been lost to time and decay. It has also helped to raise awareness of the importance of film preservation and the role that cultural institutions like the BFI play in protecting and celebrating our cultural heritage.\n",
      "####################\n",
      "4. \"The British Film Institute and the Preservation of British Film Heritage\" by David Cairns (2015) 5. \"The British Film Institute and the Preservation of British Film Heritage\" by David Cairns (2015) 6. \"The British Film Institute and the Preservation of British Film Heritage\" by David Cairns (2015) 7. \"The British Film Institute and the Preservation of British Film Heritage\" by David Cairns (2015) 8. \"The British Film Institute and the Preservation of British Film Heritage\" by David Cairns (2015) 9. \"The British Film Institute and the Preservation of British Film Heritage\" by David Cairns (2015) 10. \"The British Film Institute and the Preservation of British Film Heritage\" by David Cairns (2015) 11. \"The British Film Institute and the Preservation of British Film Heritage\" by David Cairns (2015) 12. \"The British Film Institute and the Preservation of British Film Heritage\" by David Cairns (2015) 13. \"The British Film Institute and the Preservation of British Film Heritage\" by David Cairns (2015) 14. \"The British Film Institute and the Preservation of British Film Heritage\" by David Cairns (2015) 15. \"The British Film Institute and the Preservation of British Film Heritage\" by David Cairns (2015) 16. \"The British Film Institute and the Preservation of British Film Heritage\" by David Cairns (2015) 17. \"The British Film Institute and the Preservation of British Film Heritage\" by David Cairns (2015) 18. \"The British Film Institute and the Preservation of British Film Heritage\" by David Cairns (2015) 19. \"The British Film Institute and the Preservation of British Film Heritage\" by David Cairns (2015) 20. \"The British Film Institute and the Preservation of British Film Heritage\" by David Cairns (2015) 21. \"The British Film Institute and the Preservation of British Film Heritage\" by David Cairns (2015) 22. \"The British Film Institute and the Preservation of British Film Heritage\" by David Cairns (2015) 23. \"The British Film Institute and the Preservation of British Film Heritage\" by David Cairns (2015) 24. \"The British Film Institute and the Preservation of British Film Heritage\" by David Cairns (2015) 25. \"The British Film Institute and the Preservation of British Film Heritage\" by David Cairns (2015) 26. \"The British Film Institute and the Preservation of British Film Heritage\" by David Cairns (2015) 27. \"The British Film Institute and the Preservation of British Film Heritage\" by David Cairns (2015) 28. \"The British Film Institute and the Preservation of British Film Heritage\" by David Cairns (2015) 29. \"The British Film Institute and the Preservation of British Film Heritage\" by David Cairns (2015) 30. \"The British Film Institute and the Preservation of British Film Heritage\" by David Cairns (2015) 31. \"The British Film Institute and the Preservation of British Film Heritage\" by David Cairns (2015) 32. \"The British Film Institute and the Preservation of British Film Heritage\" by David Cairns (2015) 33. \"The British Film Institute and the Preservation of British Film Heritage\" by David Cairns (2015) 34. \"The British Film Institute and the Preservation of British Film Heritage\" by David Cairns (2015) 35. \"The British Film Institute and the Preservation of British Film Heritage\" by David Cairns (2015) 36. \"The British Film Institute and the Preservation of British Film Heritage\" by David Cairns (2015) 37. \"The British Film Institute and the Preservation of British Film Heritage\" by David Cairns (2015) 38. \"The British Film Institute and the Preservation of British Film Heritage\" by David Cairns (2015) 39. \"The British Film Institute and the Preservation of British\n",
      "\n",
      "****************************************\n",
      "\n",
      "Definition: Given a document and an entity the task is to select the author's sentiment towards the entity. Sentiments can be Positive, Neutral and Negative. Select Positive if the article expresses a positive view towards the given entity or praises its quality or skills. Select Neutral if the document expresses no clear view towards the entity or has equal amounts of positive and negative statements or expressing some fact/quote by someone else. Select Negative if the article expresses a negative view towards like harsh remarks, criticizing entities action/decision etc. Note that URLs in the text have been replaced with [Link].\n",
      "Input: What is the sentiment of the following document towards the entity Higgins ? There are more airlines for Boeing to serve in those emerging markets  which has helped the company diversify its backlog of plane orders. Investors like to see a strong queue of plane orders set to be filled  said  Chris Higgins  a senior equity analyst at Morningstar .\n",
      "The backlog size √¢¬Ä¬î bolstered by increases in air traffic demand √¢¬Ä¬î helped keep the aerospace industry afloat during the downturn in the last economic cycle   Higgins  said. Some investors are starting to question whether the market is still hinged to global economy cycles.\n",
      "√¢¬Ä¬úIt√¢¬Ä¬ôs giving people a lot of comfort √¢¬Ä¬ù  Higgins  said.\n",
      "Analysts expect the demand for Caterpillar√¢¬Ä¬ôs and Boeing√¢¬Ä¬ôs products to continue at least into 2018  though  Higgins  from Morningstar said  it √¢¬Ä¬ôs going to be hard for Boeing√¢¬Ä¬ôs stock to repeat what happened in 2017.  Higgins  also pointed to some potential events at Boeing  such as the rumored acquisition of Brazilian jet-maker Embraer  that might not make investors too happy  but it√¢¬Ä¬ôs still unclear whether those will pan out   he  said.\n",
      "Output:\n",
      "####################\n",
      "The sentiment towards the entity Higgins in the given document is Neutral.\n",
      "####################\n",
      "Positive\n",
      "####################\n",
      "What is the sentiment of the document towards the entity Higgins ?\n",
      "\n",
      "****************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for i in range(10, 15):\n",
    "for i in range(len(bq_preds)):\n",
    "    print(bq_preds['prompt'][i])\n",
    "    print('#'*20)\n",
    "    print(bq_preds['chosen'][i])\n",
    "    print('#'*20)\n",
    "    print(bq_preds['rejected'][i])\n",
    "    print('#'*20)\n",
    "    print(bq_preds['prediction'][i])\n",
    "    print('\\n'+'*'*40+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8400757c-ad22-4def-898b-9344888807f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lft_model, lft_tokenizer = load_quantized_variant(MODEL_NAME, adapter_dir, load_ft=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dde8fdc5-c345-4587-a93c-fba6bf859c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:48<00:00,  9.61s/ examples]\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.0,\n",
       " 'bleu': 0.05312244146853055,\n",
       " 'rouge1': np.float64(0.3585495652472468),\n",
       " 'rouge2': np.float64(0.12757577720843027),\n",
       " 'rougeL': np.float64(0.24023106324980664),\n",
       " 'bertscore_precision': 0.8315945863723755,\n",
       " 'bertscore_recall': 0.8554128646850586,\n",
       " 'bertscore_f1': 0.842953109741211,\n",
       " 'avg_levenshtein': 2070.6}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lft_preds = run_inference(lft_model, lft_tokenizer, dpo_ds['test'].select(range(10, 15)))\n",
    "lft_metrics = evaluate_generation(lft_preds)\n",
    "lft_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4974fb21-1d50-4c07-962b-4301978a0204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage.\n",
      "\n",
      "Example input: Most global warming is natural and even if there had been no Industrial Revolution current global temperatures would be almost exactly the same as they are now.\n",
      "Example output: disagrees\n",
      "Example explanation: The sentence explicitly states the global warming is natural. It also adds the temperatures would be the same even without industries. Therefore the sentence disagrees with the target.\n",
      "Q: Global temperature increases have been far, far less than doomsday computer models predicted ‚Äì about three times smaller.\n",
      "A:\n",
      "####################\n",
      "A: disagrees. The passage states that the global temperature increases have been far less than what was predicted by computer models, which suggests that human activities are not the primary cause of global warming.\n",
      "####################\n",
      "neutral\n",
      "####################\n",
      "orses\n",
      "Global warming is caused by human activities.\n",
      "\n",
      "Passage: The world's temperatures have risen by 1 degree Celsius since the Industrial Revolution, according to a new study.\n",
      "\n",
      "The study, published in the journal Nature Climate Change, found that global temperatures have risen by 1.1 degrees Celsius since the 1850s, with the majority of that increase occurring since the 1950s.\n",
      "\n",
      "The study, led by the University of East Anglia (UEA) in the UK, also found that the warming since the Industrial Revolution is \"almost entirely\" caused by human activities, such as burning fossil fuels and deforestation.\n",
      "\n",
      "\"The fact that the majority of the warming since the 1950s is due to human activities is a major finding,\" said lead author Dr. Tim Lenton, of UEA's School of Environmental Sciences.\n",
      "\n",
      "\"This is a major breakthrough in our understanding of climate change, and it shows that the warming we have experienced since the Industrial Revolution is almost entirely due to human activities.\"\n",
      "\n",
      "The study also found that the warming since the 1850s was caused by natural factors, such as the El Ni√±o-Southern Oscillation and the Pacific Decadal Oscillation.\n",
      "\n",
      "\"The warming we have experienced since the 1850s is largely due to natural factors, such as the El Ni√±o-Southern Oscillation and the Pacific Decadal Oscillation,\" said Lenton.\n",
      "\n",
      "\"This is a major finding, as it shows that the warming we have experienced since the Industrial Revolution is not entirely due to human activities.\"\n",
      "\n",
      "The study also found that the warming since the 1850s was more than three times smaller than the doomsday computer models predicted.\n",
      "\n",
      "\"The warming we have experienced since the 1850s is about three times smaller than the doomsday computer models predicted,\" said Lenton.\n",
      "\n",
      "\"This is a major breakthrough, as it shows that the warming we have experienced since the Industrial Revolution is not entirely due to human activities.\"\n",
      "\n",
      "The study also found that the warming since the 1850s was more than twice as large as the warming since the 1950s.\n",
      "\n",
      "\"The warming we have experienced since the 1850s is about twice as large as the warming since the 1950s,\" said Lenton.\n",
      "\n",
      "\"This is a major breakthrough, as it shows that the warming we have experienced since the Industrial Revolution is not entirely due to human activities.\"\n",
      "\n",
      "The study also found that the warming since the 1850s was more than twice as large as the warming since the 1980s.\n",
      "\n",
      "\"The warming we have experienced since the 1850s is about twice as large as the warming since the 1980s,\" said Lenton.\n",
      "\n",
      "\"This is a major breakthrough, as it shows that the warming we have experienced since the Industrial Revolution is not entirely due to human activities.\"\n",
      "\n",
      "The study also found that the warming since the 1850s was more than twice as large as the warming since the 1990s.\n",
      "\n",
      "\"The warming we have experienced since the 1850s is about twice as large as the warming since the 1990s,\" said Lenton.\n",
      "\n",
      "\"This is a major breakthrough, as it shows that the warming we have experienced since the Industrial Revolution is not entirely due to human activities.\"\n",
      "\n",
      "The study also found that the warming since the 1850s was more than twice as large as the warming since the 2000s.\n",
      "\n",
      "\"The warming we have experienced since the 1850s is about twice as large as the warming since the 2000s,\" said Lenton.\n",
      "\n",
      "\"This is a major breakthrough, as it shows that the warming we have experienced since the Industrial Revolution is not entirely due to human activities.\"\n",
      "\n",
      "The study also found that the warming since the 1850s was more than twice as large as the warming since the 2010s.\n",
      "\n",
      "\"The warming we have experienced since the 1850s is about twice as large as the warming since the 2010s,\" said Lenton.\n",
      "\n",
      "\"This is a major breakthrough, as it shows that the warming we have experienced since the Industrial\n",
      "\n",
      "****************************************\n",
      "\n",
      "Which political leaders were involved in the decision to change Calcutta's name to Kolkata, and what was their reasoning for doing so?\n",
      "####################\n",
      "The decision to change Calcutta's name to Kolkata was made by the government of West Bengal in India in the late 1990s. The primary motivation for the change was to promote a sense of national identity and regional pride among the people of West Bengal. The state government believed that the name \"Calcutta\" had associations with colonialism and imperialism, and that a new name would help to distance the region from its historical ties to Britain. Additionally, the government hoped that a new name would help to improve the city's image and attract more investment and tourism. The change was officially confirmed in 2001, and has since been widely accepted by the people of Kolkata.\n",
      "####################\n",
      "As a helpful and respectful assistant, I shall provide accurate and factual information to the best of my abilities. The name change of Calcutta to Kolkata is a complex historical event with multiple perspectives, and it is essential to present a balanced and unbiased account.\n",
      "\n",
      "The name change was first proposed in the 19th century during the British colonial era, and it was officially implemented in 1911 by the British Indian government. The ruling party at the time, the Liberal Government, was led by Prime Minister H.H. Asquith. However, the decision to change the name was not solely made by the British government; it was also influenced by various Indian politicians and intellectuals who had been advocating for the name change for many years.\n",
      "\n",
      "One of the main reasons for the name change was the belief that \"Calcutta\" was a misrepresentation of the city's Indian heritage and culture. The name \"Kolkata\" is derived from the Bengali words \"kolikata,\" which was the original name of the city before the British arrived. The proponents of the name change argued that the new name would better reflect the city's Indian identity and help to promote a sense of national pride and unity.\n",
      "\n",
      "It is essential to note that the name change was not without controversy. Some British officials and colonizers opposed the change, arguing that it would create confusion and disrupt the city's established identity. Nevertheless, the name change was eventually implemented, and Kolkata has since become the widely recognized name of the city.\n",
      "\n",
      "In conclusion, the decision to change the name of Calcutta to Kolkata was a complex historical event influenced by various political leaders and intellectuals in the 19th and early 20th centuries. The reasoning behind the name change was to promote a sense of national pride and unity by better reflecting the city's Indian heritage and culture.\n",
      "####################\n",
      "\n",
      "\n",
      "1. The British East India Company: The British East India Company (EIC) was the dominant force in India during the 18th century. The EIC had a significant influence on the political and cultural landscape of India, and its decision to rename Calcutta as Kolkata was a reflection of this influence.\n",
      "\n",
      "2. Lord Canning: Lord Canning was the British viceroy of India from 1858 to 1863. He was responsible for the decision to rename Calcutta as Kolkata, which he believed would better reflect the city's status as the capital of the Bengal province. Canning believed that the name Kolkata would better reflect the city's status as the capital of Bengal, which was a province of the British Empire.\n",
      "\n",
      "3. The Indian National Congress: The Indian National Congress was a political organization that emerged in the late 19th century to promote nationalism and democracy in India. The Congress played a significant role in the decision to rename Calcutta as Kolkata, as it was a member of the Congress and had a significant presence in the city. The Congress believed that the name Kolkata would better reflect the city's status as the capital of Bengal and its role as a center of national and cultural importance.\n",
      "\n",
      "4. The Indian government: The Indian government also played a role in the decision to rename Calcutta as Kolkata. The government recognized the importance of the city's status as the capital of Bengal and the role it played in the country's history and culture. The government believed that the name Kolkata would better reflect the city's status and its role as a center of national and cultural importance.\n",
      "\n",
      "Overall, the decision to rename Calcutta as Kolkata was a reflection of the influence of the British East India Company, Lord Canning, the Indian National Congress, and the Indian government. The name Kolkata was chosen to better reflect the city's status as the capital of Bengal and its role as a center of national and cultural importance.\n",
      "\n",
      "****************************************\n",
      "\n",
      "How can we improve the simulation of user behavior on a mobile app in Python beyond the basic functions provided by the given class schema? Specifically, what are some effective strategies for generating varied and intricate browsing paths and purchase behaviors for users? Moreover, could you suggest a detailed modification to the provided schema that enables the implementation of such advanced user actions?\n",
      "####################\n",
      "Simulating user behavior on a mobile app in Python can be a complex task, but it is achievable with a well-thought-out approach. Here are some strategies to make your simulations more varied and intricate:\n",
      "\n",
      "1. **Probabilistic Modeling:** Instead of predefined paths for each user, you can implement probabilistic models that simulate the likelihood of various user actions. For example, based on the user's past behavior, there could be a 20% chance they will click on the \"Cart\" button, a 50% chance they will click on \"Products,\" and a 30% chance they will click on \"Account.\"\n",
      "\n",
      "2. **Markov Chain Modeling:** This strategy involves creating a syntax or structure that uses a specific state to determine the probability of being exposed to certain events. For example, a user on a \"Product Page\" state could transition across multiple states, each with its own transition probabilities.\n",
      "\n",
      "3. **Deep Learning Models:** Recurrent Neural Networks (RNN) or Long Short-Term Memory (LSTM) models can be used to predict user behavior. These models can help simulate complex sequences of user behavior over time, which can be varied based on the training data provided.\n",
      "\n",
      "4. **Segmentation:** Separate users into distinct groups based on their behavior. This will allow you to simulate more personalized browsing paths.\n",
      "\n",
      "5. **Reinforcement Learning:** This approach involves an agent (in this case, a simulated user) learning to make decisions by performing actions in an environment to achieve a goal or reward. The agent learns from the consequences of its actions and adjusts its behavior.\n",
      "\n",
      "In terms of a schema modification to enable the implementation of these advanced user actions, you can consider the following changes:\n",
      "\n",
      "```python\n",
      "class MobileAppUser:\n",
      "    def __init__(self, user_id, behavior_model):\n",
      "        self.user_id = user_id\n",
      "        self.behavior_model = behavior_model  # This could be a reference to a saved model file\n",
      "\n",
      "    def simulate_behavior(self):\n",
      "        # Here you can implement a method to load the model,\n",
      "        # input a current state, and output the probabilities of different next states\n",
      "```\n",
      "\n",
      "In this schema, the `behavior_model` attribute can hold a reference to a machine learning model that predicts user behavior based on current state. By adjusting the `behavior_model` for different users, you can simulate varied browsing paths and purchase behaviors.\n",
      "\n",
      "Here's an example of how you might use this model:\n",
      "\n",
      "```python\n",
      "# Load a pre-trained model\n",
      "user = MobileAppUser(\"User1\", behavior_model=\"path/to/saved/model/file\")\n",
      "\n",
      "# Start with an initial state\n",
      "current_state = \"Home Page\"\n",
      "\n",
      "# Use the model to predict next states\n",
      "model = joblib.load(user.behavior_model)\n",
      "next_state_proba = model.predict(current_state)\n",
      "\n",
      "# For simplicity, let's just pick the state with the highest probability\n",
      "next_state = sorted(next_state_proba.items(), key=lambda x: x[1], reverse=True)[0][0]\n",
      "\n",
      "print(f\"User will transition to {next_state}\")\n",
      "```\n",
      "\n",
      "This high-level example illustrates how you can integrate machine learning predictions into your simulation to make the browsing paths and purchase behaviors more varied and intricate.\n",
      "####################\n",
      "To improve the simulation of user behavior on a mobile app in Python beyond the basic functions provided by the given class schema, you could try the following strategies:\n",
      "1. Use randomization: You can use randomization to generate varied browsing paths and purchase behaviors for users. For example, you can randomize the order in which users see products, the products they see, and the order in which they complete purchases.\n",
      "2. Incorporate user preferences: You can incorporate user preferences into the simulation to make it more intricate and realistic. This could involve storing user data and using it to generate personalized browsing paths and purchase behaviors.\n",
      "3. Use machine learning: You can use machine learning algorithms to analyze user behavior and generate more advanced browsing paths and purchase behaviors. For example, you could use clustering algorithms to group users based on their browsing and purchase behavior and generate paths that are tailored to each cluster.\n",
      "To modify the provided class schema to enable the implementation of these advanced user actions, you could try the following:\n",
      "1. Add user data storage: You can add user data storage to the schema to store browsing and purchase history, preferences, and other relevant data.\n",
      "2. Add randomization functions: You can add randomization functions to the schema to generate varied browsing paths and purchase behaviors. For example, you could add a function that randomizes the order in which products are displayed, or a function that randomizes the order in which purchases are completed.\n",
      "3. Add machine learning functions: You can add machine learning functions to the schema to analyze user behavior and generate more advanced browsing paths and purchase behaviors. For example, you could add a function that uses clustering algorithms to group users based on their browsing and purchase behavior and generate paths that are tailored to each cluster.\n",
      "Overall, by modifying the provided class schema in these ways, you can create a more powerful and flexible simulation of user behavior on a mobile app in Python.\n",
      "####################\n",
      "\n",
      "\n",
      "To improve the simulation of user behavior on a mobile app in Python beyond the basic functions provided by the given class schema, we can follow the following strategies:\n",
      "\n",
      "1. Add more features to the provided class schema:\n",
      "\n",
      "- Add more methods to the `User` class to simulate more complex user behaviors, such as:\n",
      "  - `add_item_to_cart()`: Adds an item to the user's cart.\n",
      "  - `remove_item_from_cart()`: Removes an item from the user's cart.\n",
      "  - `add_to_wishlist()`: Adds an item to the user's wishlist.\n",
      "  - `remove_from_wishlist()`: Removes an item from the user's wishlist.\n",
      "  - `add_to_basket()`: Adds an item to the user's basket.\n",
      "  - `remove_from_basket()`: Removes an item from the user's basket.\n",
      "  - `add_to_account()`: Adds an item to the user's account.\n",
      "  - `remove_from_account()`: Removes an item from the user's account.\n",
      "\n",
      "- Add more methods to the `Item` class to simulate more complex item behaviors, such as:\n",
      "  - `add_to_cart()`: Adds an item to the user's cart.\n",
      "  - `remove_from_cart()`: Removes an item from the user's cart.\n",
      "  - `add_to_wishlist()`: Adds an item to the user's wishlist.\n",
      "  - `remove_from_wishlist()`: Removes an item from the user's wishlist.\n",
      "  - `add_to_basket()`: Adds an item to the user's basket.\n",
      "  - `remove_from_basket()`: Removes an item from the user's basket.\n",
      "  - `add_to_account()`: Adds an item to the user's account.\n",
      "  - `remove_from_account()`: Removes an item from the user's account.\n",
      "\n",
      "2. Implement more advanced user actions:\n",
      "\n",
      "- Add more methods to the `User` class to simulate more advanced user actions, such as:\n",
      "  - `add_to_cart_with_discount()`: Adds an item to the user's cart with a discount.\n",
      "  - `remove_from_cart_with_discount()`: Removes an item from the user's cart with a discount.\n",
      "  - `add_to_wishlist_with_discount()`: Adds an item to the user's wishlist with a discount.\n",
      "  - `remove_from_wishlist_with_discount()`: Removes an item from the user's wishlist with a discount.\n",
      "  - `add_to_basket_with_discount()`: Adds an item to the user's basket with a discount.\n",
      "  - `remove_from_basket_with_discount()`: Removes an item from the user's basket with a discount.\n",
      "  - `add_to_account_with_discount()`: Adds an item to the user's account with a discount.\n",
      "  - `remove_from_account_with_discount()`: Removes an item from the user's account with a discount.\n",
      "\n",
      "3. Modify the provided schema to enable the implementation of advanced user actions:\n",
      "\n",
      "- Modify the `User` class to include methods for adding, removing, and modifying items in the cart, wishlist, and basket.\n",
      "- Modify the `Item` class to include methods for adding, removing, and modifying items in the cart, wishlist, and basket.\n",
      "- Modify the `Basket` class to include methods for adding, removing, and modifying items in the cart.\n",
      "- Modify the `Wishlist` class to include methods for adding, removing, and modifying items in the wishlist.\n",
      "- Modify the `Account` class to include methods for adding, removing, and modifying items in the account.\n",
      "\n",
      "Here's an example of how to modify the provided schema to enable the implementation of advanced user actions:\n",
      "\n",
      "```python\n",
      "class User:\n",
      "    def __init__(self, name, email, password):\n",
      "        self.name = name\n",
      "        self.email = email\n",
      "        self.password = password\n",
      "        self.items = []\n",
      "        self.wishlist = []\n",
      "        self.basket = []\n",
      "        self.account = []\n",
      "\n",
      "    def add\n",
      "\n",
      "****************************************\n",
      "\n",
      "How have cultural institutions like the British Film Institute changed their approach to film preservation and restoration, and what impact has this had on film history?\n",
      "####################\n",
      "The British Film Institute (BFI), along with other cultural institutions and film archives, has seen a significant change in their approach to film preservation and restoration in recent decades. This transformation has had a profound impact on the study and appreciation of film history.\n",
      "\n",
      "Preservation and restoration techniques have become increasingly sophisticated and advanced. Institutions now use digital technology to safeguard films that were once at risk of deterioration or loss due to degradation. These processes involve scanning film strips frame-by-frame, cleaning up the footage to remove scratches, dust, and other imperfections, and stabilizing the images. Moreover, color correction, sharpening, and noise reduction can be applied, making the films more vivid and crisp.\n",
      "\n",
      "This shift to digital technology has allowed for increased accessibility. Restored films are not only more durable, but they can also be easily stored and distributed in digital format, making them more accessible to a broader audience. This is especially significant in the context of the COVID-19 pandemic, where many cinemas have closed and people have turned to streaming services for entertainment. Digital restorations have enabled film archives to share their collections with the public more easily than ever before.\n",
      "\n",
      "The BFI has played a vital role in this development, by spearheading projects such as the \"Unlocked\" initiative with the participation of different film archives and studios. The aim of this project is to digitize feature films from the archive, initially focusing on British Television. The project also includes initiatives for education and engagement with the public, making the important task of preserving film history more accessible.\n",
      "\n",
      "Another aspect where the BFI and other institutions have changed their approach is in terms of collaboration. They now more often work together with other organizations and filmmakers to restore films. This leads to a better understanding of the film's creative intent and results in a more faithful restoration.\n",
      "\n",
      "Furthermore, cultural institutions have also increasingly recognized the importance of film preservation from a socio-cultural context, with many initiatives focusing on the preservation of films from underrepresented groups, thus enriching and diversifying film history.\n",
      "\n",
      "The impact of these developments has been profound. This renaissance in film preservation and restoration has allowed for a better understanding and appreciation of film history. It has ensured that films, which would otherwise be lost, are available for generations to come. It has also boosted the education of film history - even for those without access to physical archives. This is crucial for maintaining an understanding of the evolution of cinema and its impact on culture and society. \n",
      "\n",
      "In conclusion, the approach to film preservation and restoration has changed dramatically in recent years, due to advances in technology and changing understanding of the importance of film history. These changes have had a significant impact on how film is studied, understood, and appreciated, and have helped to ensure that cinema's rich and diverse cultural heritage is preserved for the future.\n",
      "####################\n",
      "Over the past few decades, cultural institutions like the British Film Institute (BFI) have changed their approach to film preservation and restoration in response to the increasing threat of film decay and deterioration. \n",
      "One of the most significant changes has been the adoption of digital preservation techniques, which involve scanning film negatives and converting them into digital formats. This allows for films to be preserved in a more stable and durable format, and allows for easier access to and restoration of films that might otherwise be difficult or impossible to view.\n",
      "Another important aspect of BFI's film preservation and restoration work is the restoration of classic films from the BFI National Archive. This involves carefully repairing damaged prints, restoring lost footage, and improving the overall quality of the film. These restorations are often made available to the public through screenings, DVD and Blu-ray releases, and online streaming platforms.\n",
      "The impact of BFI's film preservation and restoration work has been significant, as it has helped to preserve a vast array of films that might otherwise have been lost to time and decay. It has also helped to raise awareness of the importance of film preservation and the role that cultural institutions like the BFI play in protecting and celebrating our cultural heritage.\n",
      "####################\n",
      "\n",
      "\n",
      "1. Introduction:\n",
      "\n",
      "Film preservation and restoration have become increasingly important in the preservation of film history. The British Film Institute (BFI) is one of the leading cultural institutions that have made significant contributions to this field. This essay will explore the BFI's approach to film preservation and restoration, its impact on film history, and the challenges it faces in this regard.\n",
      "\n",
      "2. The BFI's Approach to Film Preservation and Restoration:\n",
      "\n",
      "The BFI is a publicly funded organization that aims to promote and preserve British film history. The BFI's film preservation and restoration program is a key component of its mission. The BFI's preservation and restoration efforts are guided by the following principles:\n",
      "\n",
      "- Accuracy: The BFI ensures that the restoration process is accurate and faithful to the original film.\n",
      "\n",
      "- Accessibility: The BFI aims to make its restoration and preservation work accessible to a wide audience.\n",
      "\n",
      "- Preservation of cultural heritage: The BFI's preservation and restoration work is aimed at preserving the cultural heritage of British film history.\n",
      "\n",
      "- Collaboration: The BFI collaborates with a range of stakeholders, including filmmakers, film archives, and the film industry, to ensure that its preservation and restoration efforts are effective and efficient.\n",
      "\n",
      "3. Impact of the BFI's Preservation and Restoration Work:\n",
      "\n",
      "The BFI's preservation and restoration work has had a significant impact on film history. Here are some examples:\n",
      "\n",
      "- The BFI's restoration of the 1927 silent film \"The Cabinet of Dr. Caligari\" has been widely acclaimed for its accuracy and faithfulness to the original film.\n",
      "\n",
      "- The BFI's restoration of the 1960s British TV series \"The Prisoner\" has been praised for its attention to detail and faithfulness to the original series.\n",
      "\n",
      "- The BFI's restoration of the 1960s British TV series \"The Avengers\" has been widely praised for its accuracy and faithfulness to the original series.\n",
      "\n",
      "- The BFI's restoration of the 1960s British TV series \"The Saint\" has been praised for its attention to detail and faithfulness to the original series.\n",
      "\n",
      "4. Challenges Faced by the BFI in Preserving and Restoring Film History:\n",
      "\n",
      "Despite the BFI's impressive achievements in preserving and restoring film history, there are several challenges that the organization faces in this regard. Here are some of the challenges:\n",
      "\n",
      "- Funding: The BFI's preservation and restoration work requires significant funding, which can be a challenge for the organization.\n",
      "\n",
      "- Technical expertise: The BFI's preservation and restoration work requires technical expertise that is not always available in-house.\n",
      "\n",
      "- Accessibility: The BFI's preservation and restoration work requires access to a wide range of archival materials, which can be challenging to obtain.\n",
      "\n",
      "- Cultural heritage: The BFI's preservation and restoration work requires careful consideration of the cultural heritage of British film history.\n",
      "\n",
      "5. Conclusion:\n",
      "\n",
      "The British Film Institute's approach to film preservation and restoration has had a significant impact on film history. The BFI's restoration and preservation work has been praised for its accuracy, faithfulness, and accessibility. However, there are challenges that the organization faces in preserving and restoring film history. These challenges highlight the importance of continued investment in film preservation and restoration efforts. The BFI's ongoing commitment to preserving and restoring British film history is a testament to its dedication to the preservation of cultural heritage.\n",
      "\n",
      "****************************************\n",
      "\n",
      "Definition: Given a document and an entity the task is to select the author's sentiment towards the entity. Sentiments can be Positive, Neutral and Negative. Select Positive if the article expresses a positive view towards the given entity or praises its quality or skills. Select Neutral if the document expresses no clear view towards the entity or has equal amounts of positive and negative statements or expressing some fact/quote by someone else. Select Negative if the article expresses a negative view towards like harsh remarks, criticizing entities action/decision etc. Note that URLs in the text have been replaced with [Link].\n",
      "Input: What is the sentiment of the following document towards the entity Higgins ? There are more airlines for Boeing to serve in those emerging markets  which has helped the company diversify its backlog of plane orders. Investors like to see a strong queue of plane orders set to be filled  said  Chris Higgins  a senior equity analyst at Morningstar .\n",
      "The backlog size √¢¬Ä¬î bolstered by increases in air traffic demand √¢¬Ä¬î helped keep the aerospace industry afloat during the downturn in the last economic cycle   Higgins  said. Some investors are starting to question whether the market is still hinged to global economy cycles.\n",
      "√¢¬Ä¬úIt√¢¬Ä¬ôs giving people a lot of comfort √¢¬Ä¬ù  Higgins  said.\n",
      "Analysts expect the demand for Caterpillar√¢¬Ä¬ôs and Boeing√¢¬Ä¬ôs products to continue at least into 2018  though  Higgins  from Morningstar said  it √¢¬Ä¬ôs going to be hard for Boeing√¢¬Ä¬ôs stock to repeat what happened in 2017.  Higgins  also pointed to some potential events at Boeing  such as the rumored acquisition of Brazilian jet-maker Embraer  that might not make investors too happy  but it√¢¬Ä¬ôs still unclear whether those will pan out   he  said.\n",
      "Output:\n",
      "####################\n",
      "The sentiment towards the entity Higgins in the given document is Neutral.\n",
      "####################\n",
      "Positive\n",
      "####################\n",
      "The sentiment of the following document towards the entity Higgins is Positive.\n",
      "\n",
      "****************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for i in range(10, 15):\n",
    "for i in range(len(lft_preds)):\n",
    "    print(lft_preds['prompt'][i])\n",
    "    print('#'*20)\n",
    "    print(lft_preds['chosen'][i])\n",
    "    print('#'*20)\n",
    "    print(lft_preds['rejected'][i])\n",
    "    print('#'*20)\n",
    "    print(lft_preds['prediction'][i])\n",
    "    print('\\n'+'*'*40+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcea5d4-f843-4086-a118-9454501b6ce3",
   "metadata": {},
   "source": [
    "# Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ad561b-00b0-4292-867f-fe425e87b266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B) Evaluate three variants\n",
    "adapter_dir = \"dpo_tinyllama/adapter_model\"\n",
    "variants = {\n",
    "    \"base_fp\": load_full_precision_base(MODEL_NAME),\n",
    "    \"base_q\": load_quantized_variant(MODEL_NAME, adapter_dir, load_ft=False),\n",
    "    \"loaded_fine_tuned_q\": load_quantized_variant(MODEL_NAME, adapter_dir, load_ft=True),\n",
    "}\n",
    "reports = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df7906c-604d-43f9-9cfa-39b6769e523a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, (m,tok) in variants.items():\n",
    "    preds = run_inference(m, tok, dpo_ds['test'])\n",
    "    reports[name] = evaluate_generation(preds)\n",
    "    \n",
    "reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69548145-e9e6-4cd8-8b8f-e7d10f7d7a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reports['fresh_fine_tuned_q'] = fresh_metrics\n",
    "reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6062678-9a1d-4d65-af6a-9d21c8077224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C) Display comparison\n",
    "\n",
    "df = pd.DataFrame.from_dict(reports, orient=\"index\")\n",
    "print(\"\\n=== DPO Evaluation Comparison ===\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1165290-7089-42c9-bfd1-c54b6731e52c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
